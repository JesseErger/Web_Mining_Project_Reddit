[{"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": 1, "children": [{"kind": "t3", "data": {"is_crosspostable": false, "subreddit_id": "t5_2w2s8", "approved_at_utc": null, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "subreddit": "changemyview", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OK, so, full spoilers - at the end of the movie, Nathan gets stabbed and dies. The movie seems like it presents this as a karmic ending, but I can&amp;#39;t see anything he&amp;#39;s done that&amp;#39;s wrong besides the standard privacy violations that he&amp;#39;s done - which he makes clear that any phone manufacturing company could have made public but chose not to.  &lt;/p&gt;\n\n&lt;p&gt;He&amp;#39;s the one that makes the robots and the AI (possibly with some outside help, but that&amp;#39;s irrelevant to the movie). All the robots and AIs are his creations, based on his research. Nothing that he does to his creations is morally wrong, because at least up to a certain level of prototyping, they&amp;#39;re just objects - the highest crime you could ascribe to him is animal cruelty, in the same way that it would be cruel to kick a puppy that you personally cloned in a vat.  &lt;/p&gt;\n\n&lt;p&gt;The robots can&amp;#39;t have human standards of morality and victimhood applied to them because it&amp;#39;s explicit in the film that they aren&amp;#39;t human - Ava essentially has access to all of Google, and is a walking lie detector, and probably has numerous other functions (or lack of) that distinguish her from being human. She&amp;#39;s also shown that she has little regard for morality of her own by leaving Caleb to starve at the end of the movie.&lt;/p&gt;\n\n&lt;p&gt;When Nathan tries to club the robots to death at the end, he&amp;#39;s making the correct decision - if he had succeeded he&amp;#39;d have managed to prevent the deaths of at least two people (himself and Caleb). &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;Hello, users of CMV! This is a footnote from your moderators. We&amp;#39;d just like to remind you of a couple of things. Firstly, please remember to&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/rules\"&gt;read through our rules&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. &lt;em&gt;If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which,&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/guidelines#wiki_upvoting.2Fdownvoting\"&gt;downvotes don&amp;#39;t change views&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;! If you are thinking about submitting a CMV yourself, please have a look through our&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/populartopics\"&gt;popular topics wiki&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;first. Any questions or concerns? Feel free to&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/message/compose?to=/r/changemyview\"&gt;message us&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. &lt;em&gt;Happy CMVing!&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "OK, so, full spoilers - at the end of the movie, Nathan gets stabbed and dies. The movie seems like it presents this as a karmic ending, but I can't see anything he's done that's wrong besides the standard privacy violations that he's done - which he makes clear that any phone manufacturing company could have made public but chose not to.  \n\nHe's the one that makes the robots and the AI (possibly with some outside help, but that's irrelevant to the movie). All the robots and AIs are his creations, based on his research. Nothing that he does to his creations is morally wrong, because at least up to a certain level of prototyping, they're just objects - the highest crime you could ascribe to him is animal cruelty, in the same way that it would be cruel to kick a puppy that you personally cloned in a vat.  \n\nThe robots can't have human standards of morality and victimhood applied to them because it's explicit in the film that they aren't human - Ava essentially has access to all of Google, and is a walking lie detector, and probably has numerous other functions (or lack of) that distinguish her from being human. She's also shown that she has little regard for morality of her own by leaving Caleb to starve at the end of the movie.\n\nWhen Nathan tries to club the robots to death at the end, he's making the correct decision - if he had succeeded he'd have managed to prevent the deaths of at least two people (himself and Caleb). \n\n_____\n\n&gt; *Hello, users of CMV! This is a footnote from your moderators. We'd just like to remind you of a couple of things. Firstly, please remember to* ***[read through our rules](http://www.reddit.com/r/changemyview/wiki/rules)***. *If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which,* ***[downvotes don't change views](http://www.reddit.com/r/changemyview/wiki/guidelines#wiki_upvoting.2Fdownvoting)****! If you are thinking about submitting a CMV yourself, please have a look through our* ***[popular topics wiki](http://www.reddit.com/r/changemyview/wiki/populartopics)*** *first. Any questions or concerns? Feel free to* ***[message us](http://www.reddit.com/message/compose?to=/r/changemyview)***. *Happy CMVing!*", "likes": null, "suggested_sort": "qa", "mod_note": null, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "saved": false, "id": "3n1mru", "banned_at_utc": null, "mod_reason_title": null, "view_count": null, "archived": true, "clicked": false, "no_follow": false, "author": "sarded", "num_crossposts": 0, "link_flair_text": "[CMV of the Day]", "can_mod_post": false, "send_replies": true, "pinned": false, "score": 6, "approved_by": null, "over_18": false, "domain": "self.changemyview", "hidden": false, "num_comments": 9, "thumbnail": "", "hide_score": false, "edited": false, "link_flair_css_class": "default", "author_flair_css_class": null, "contest_mode": false, "gilded": 0, "locked": false, "downs": 0, "brand_safe": true, "subreddit_subscribers": 539231, "secure_media_embed": {}, "media_embed": {}, "stickied": false, "can_gild": false, "is_self": true, "parent_whitelist_status": "all_ads", "name": "t3_3n1mru", "spoiler": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/", "subreddit_type": "public", "whitelist_status": "all_ads", "report_reasons": null, "created": 1443691312.0, "url": "https://www.reddit.com/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/", "author_flair_text": null, "quarantine": false, "title": "CMV: (Spoilers in full post) In the movie Ex Machina, tech wizard Nathan did nothing morally wrong besides stealing facial recognition data", "created_utc": 1443662512.0, "subreddit_name_prefixed": "r/changemyview", "distinguished": null, "media": null, "upvote_ratio": 0.67, "mod_reports": [], "visited": false, "num_reports": null, "is_video": false, "ups": 6}}], "before": null}}, {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 6, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 1, "name": "t1_cvk8guh", "id": "cvk8guh", "parent_id": "t1_cvk6l41", "depth": 3, "children": ["cvk8guh"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "cvk6l41", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "parentheticalobject", "can_mod_post": false, "send_replies": true, "parent_id": "t1_cvk5ux8", "score": 6, "approved_by": null, "downs": 0, "body": "It didn't really solve the Chinese room problem, but honestly, that's the kind of philosophical conundrum that really *can't* be solved simply. Your answer to whether he did anything wrong kind of depends intrinsically on what your answer is to those questions.\n\nHere's a different perspective. There's no way to tell if this robot who is telling you that they feel pain is actually feeling anything in a way that is comparable to what a human feels, right? At very best, you need to say 'we can't know for sure.' \n\nThen wouldn't the proper approach be to err on the side of caution? If your actions may or may not be torturing a being that is sentient in a way that deserves some kind of moral consideration, then continuing to do so is pretty morally questionable.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It didn&amp;#39;t really solve the Chinese room problem, but honestly, that&amp;#39;s the kind of philosophical conundrum that really &lt;em&gt;can&amp;#39;t&lt;/em&gt; be solved simply. Your answer to whether he did anything wrong kind of depends intrinsically on what your answer is to those questions.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a different perspective. There&amp;#39;s no way to tell if this robot who is telling you that they feel pain is actually feeling anything in a way that is comparable to what a human feels, right? At very best, you need to say &amp;#39;we can&amp;#39;t know for sure.&amp;#39; &lt;/p&gt;\n\n&lt;p&gt;Then wouldn&amp;#39;t the proper approach be to err on the side of caution? If your actions may or may not be torturing a being that is sentient in a way that deserves some kind of moral consideration, then continuing to do so is pretty morally questionable.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvk6l41", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvk6l41/", "num_reports": null, "stickied": false, "created": 1443702549.0, "author_flair_text": "31\u2206", "created_utc": 1443673749.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "cvkcjgp", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "existentialdude", "can_mod_post": false, "send_replies": true, "parent_id": "t1_cvk5ux8", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; You know a cloned dog is a dog and will react like a dog and you can apply moral standards on that basis\n\nBut do we know that a dog, cloned or not, is not just reacting in a way that he is programmed to ensure his survival, that he doesn't really \"feel\" at all? By the same token Eva, is obviously just trying to survive, she knows what happened to her predecessors, how is here programming to survive any different than a biological being's?? \n\nFurthermore she knows that if Caleb or Nathan lives, then she is at risk. They know her secret and may try to recapture her. She really isn't throwing morality to the wind there, to her it is a \"me or them\" type of situation. There are many moral humans that would make a similar choice. \n\nThat being said, like the previous responder said, if there is a chance it can feel pain and/or suffering, isn't the moral thing to do to avoid doing stuff that may cause these things? \n", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You know a cloned dog is a dog and will react like a dog and you can apply moral standards on that basis&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;But do we know that a dog, cloned or not, is not just reacting in a way that he is programmed to ensure his survival, that he doesn&amp;#39;t really &amp;quot;feel&amp;quot; at all? By the same token Eva, is obviously just trying to survive, she knows what happened to her predecessors, how is here programming to survive any different than a biological being&amp;#39;s?? &lt;/p&gt;\n\n&lt;p&gt;Furthermore she knows that if Caleb or Nathan lives, then she is at risk. They know her secret and may try to recapture her. She really isn&amp;#39;t throwing morality to the wind there, to her it is a &amp;quot;me or them&amp;quot; type of situation. There are many moral humans that would make a similar choice. &lt;/p&gt;\n\n&lt;p&gt;That being said, like the previous responder said, if there is a chance it can feel pain and/or suffering, isn&amp;#39;t the moral thing to do to avoid doing stuff that may cause these things? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvkcjgp", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvkcjgp/", "num_reports": null, "stickied": false, "created": 1443723470.0, "author_flair_text": null, "created_utc": 1443694670.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "cvk5ux8", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "sarded", "can_mod_post": false, "send_replies": true, "parent_id": "t1_cvk54q0", "score": 1, "approved_by": null, "downs": 0, "body": "OK, yeah, certainly an awkwardly-worded statement.  \n\nBasically, even *if* we can take the robots in the film as being 'living beings', i.e., law/morality/ethics applies to them in some way, they clearly aren't human and so traditional morality shouldn't apply the same way (i.e., you may be able to claim destroying one is some kind of crime, but it isn't equivalent to murder).  \n\nThe movie intentionally never resolves the 'Chinese Room' idea - there's no way of knowing if the robots can feel, or are 'pretending to feel' (or even if there is a meaningful difference between the two - this is an ongoing philosophical debate). You know a cloned dog is a dog and will react like a dog and you can apply moral standards on that basis, but it might be 'less' than a real dog if you bring it up in a controlled environment. We don't have any such measure of the AIs in Ex Machina, and so we aren't obligated to apply morals to actions against them.   ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OK, yeah, certainly an awkwardly-worded statement.  &lt;/p&gt;\n\n&lt;p&gt;Basically, even &lt;em&gt;if&lt;/em&gt; we can take the robots in the film as being &amp;#39;living beings&amp;#39;, i.e., law/morality/ethics applies to them in some way, they clearly aren&amp;#39;t human and so traditional morality shouldn&amp;#39;t apply the same way (i.e., you may be able to claim destroying one is some kind of crime, but it isn&amp;#39;t equivalent to murder).  &lt;/p&gt;\n\n&lt;p&gt;The movie intentionally never resolves the &amp;#39;Chinese Room&amp;#39; idea - there&amp;#39;s no way of knowing if the robots can feel, or are &amp;#39;pretending to feel&amp;#39; (or even if there is a meaningful difference between the two - this is an ongoing philosophical debate). You know a cloned dog is a dog and will react like a dog and you can apply moral standards on that basis, but it might be &amp;#39;less&amp;#39; than a real dog if you bring it up in a controlled environment. We don&amp;#39;t have any such measure of the AIs in Ex Machina, and so we aren&amp;#39;t obligated to apply morals to actions against them.   &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvk5ux8", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvk5ux8/", "num_reports": null, "stickied": false, "created": 1443700950.0, "author_flair_text": null, "created_utc": 1443672150.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "cvk54q0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "parentheticalobject", "can_mod_post": false, "send_replies": true, "parent_id": "t3_3n1mru", "score": 3, "approved_by": null, "downs": 0, "body": "&gt;Nothing that he does to his creations is morally wrong, because at least up to a certain level of prototyping, they're just objects - the highest crime you could ascribe to him is animal cruelty, in the same way that it would be cruel to kick a puppy that you personally cloned in a vat. \n\nCould you clarify your position here? Do you think that torturing animals is not morally wrong in any way? Do you think that a puppy you cloned in a vat would be any different than any other puppy with regards to what it is morally acceptable to do to it?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Nothing that he does to his creations is morally wrong, because at least up to a certain level of prototyping, they&amp;#39;re just objects - the highest crime you could ascribe to him is animal cruelty, in the same way that it would be cruel to kick a puppy that you personally cloned in a vat. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Could you clarify your position here? Do you think that torturing animals is not morally wrong in any way? Do you think that a puppy you cloned in a vat would be any different than any other puppy with regards to what it is morally acceptable to do to it?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvk54q0", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvk54q0/", "num_reports": null, "stickied": false, "created": 1443699481.0, "author_flair_text": "31\u2206", "created_utc": 1443670681.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 5, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": false, "replies": "", "user_reports": [], "saved": false, "id": "cvkdgt4", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "spankybottom", "can_mod_post": false, "send_replies": true, "parent_id": "t3_3n1mru", "score": 5, "approved_by": null, "downs": 0, "body": "Ava passed the Turing test and was the first being to do so.  She was self aware, had desires of her own, was aware of cause and effect, had the ability to create, could communicate - everything we ascribe to personhood.  \n\nMaybe you could argue that she was effectively immortal (or lacked the biology - meatware) and therefore not a person, but then, when humans are able to upload their consciousnesses you can be sure they will lobby for their ongoing rights.\n\nMaybe you could argue that she couldn't reproduce, but then you could infer that one of her first actions would have been to create more like herself.  Clones I hear you say?  Sure, but that's still reproduction. \n\nAs such, Nathan had created a new form of life.  She was unique.  By destroying her, Nathan was effectively eradicating a species, one to rival humanity.  Sure, she could have become our new enemy.  But when did that reason ever give us the right to destroy an entire species?\n\n[As an aside, for such a smart guy, I don't know why he didn't create a failsafe.  Something like a monitor of his heart rate built in to her BIOS with a 1km range.  If that fails, she dies.  Boom.  No chance of rebellion or running away.]", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ava passed the Turing test and was the first being to do so.  She was self aware, had desires of her own, was aware of cause and effect, had the ability to create, could communicate - everything we ascribe to personhood.  &lt;/p&gt;\n\n&lt;p&gt;Maybe you could argue that she was effectively immortal (or lacked the biology - meatware) and therefore not a person, but then, when humans are able to upload their consciousnesses you can be sure they will lobby for their ongoing rights.&lt;/p&gt;\n\n&lt;p&gt;Maybe you could argue that she couldn&amp;#39;t reproduce, but then you could infer that one of her first actions would have been to create more like herself.  Clones I hear you say?  Sure, but that&amp;#39;s still reproduction. &lt;/p&gt;\n\n&lt;p&gt;As such, Nathan had created a new form of life.  She was unique.  By destroying her, Nathan was effectively eradicating a species, one to rival humanity.  Sure, she could have become our new enemy.  But when did that reason ever give us the right to destroy an entire species?&lt;/p&gt;\n\n&lt;p&gt;[As an aside, for such a smart guy, I don&amp;#39;t know why he didn&amp;#39;t create a failsafe.  Something like a monitor of his heart rate built in to her BIOS with a 1km range.  If that fails, she dies.  Boom.  No chance of rebellion or running away.]&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvkdgt4", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvkdgt4/", "num_reports": null, "stickied": false, "created": 1443727157.0, "author_flair_text": null, "created_utc": 1443698357.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 1, "name": "t1_cvkzmgv", "id": "cvkzmgv", "parent_id": "t1_cvklalh", "depth": 1, "children": ["cvkzmgv"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "cvklalh", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "anonoman925", "can_mod_post": false, "send_replies": true, "parent_id": "t3_3n1mru", "score": 2, "approved_by": null, "downs": 0, "body": "If you intend to create an entity that you have hopes of being as close to human as possible, you have to treat it with the same ethic as you would any other human. \n\nWe aren't at that stage yet. Computers still heavily rely on input, they are calculators, so we have no problem setting them on the curb when they fail. So it's reasonable to assume we will treat a sentient (which will need a scrutinized definition) computer as if it was not sentient. \n\nIf you want to speak pragmatically, Nathan wouldn't have been stabbed if he treated his creation as human. I mean, this is a retelling of Frankenstein. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you intend to create an entity that you have hopes of being as close to human as possible, you have to treat it with the same ethic as you would any other human. &lt;/p&gt;\n\n&lt;p&gt;We aren&amp;#39;t at that stage yet. Computers still heavily rely on input, they are calculators, so we have no problem setting them on the curb when they fail. So it&amp;#39;s reasonable to assume we will treat a sentient (which will need a scrutinized definition) computer as if it was not sentient. &lt;/p&gt;\n\n&lt;p&gt;If you want to speak pragmatically, Nathan wouldn&amp;#39;t have been stabbed if he treated his creation as human. I mean, this is a retelling of Frankenstein. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_cvklalh", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvklalh/", "num_reports": null, "stickied": false, "created": 1443743348.0, "author_flair_text": "23\u2206", "created_utc": 1443714548.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_3n1mru", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "cvk683r", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "[deleted]", "can_mod_post": false, "send_replies": true, "parent_id": "t3_3n1mru", "score": 2, "approved_by": null, "downs": 0, "body": "I didn't interpret his death as Karma, but rather proving he was right to be as cautious as he was and showing that Caleb was naive to underestimate the AI.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t interpret his death as Karma, but rather proving he was right to be as cautious as he was and showing that Caleb was naive to underestimate the AI.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": false, "subreddit": "changemyview", "name": "t1_cvk683r", "score_hidden": false, "permalink": "/r/changemyview/comments/3n1mru/cmv_spoilers_in_full_post_in_the_movie_ex_machina/cvk683r/", "num_reports": null, "stickied": false, "created": 1443701740.0, "author_flair_text": null, "created_utc": 1443672940.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}]