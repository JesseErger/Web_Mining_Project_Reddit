[{"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": 1, "children": [{"kind": "t3", "data": {"is_crosspostable": false, "subreddit_id": "t5_2w2s8", "approved_at_utc": null, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "subreddit": "changemyview", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My view is that AI wont be a problem and that Elon Musk, Stephen Hawking, and Bill Gates&amp;#39; concerns are liken to the concerns that the first atomic blast would ignite the atmosphere, or that the first supercollider would destroy the Earth by causing an unstoppable black hole, or that literature/guns/alcohol/voting/sex will end the world and government, and all that technophobia regarding tools.&lt;/p&gt;\n\n&lt;p&gt;In these cases, and all slippery-slope cases, the problem is that the unknown is filled with ourselves, with our anxieties, and the actual capabilities of such systems are exaggerated (ego) and seen as irresistible. I think the gone-amok AI idea, appearing beforehand in SciFi, became serious when &lt;a href=\"http://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29\"&gt;Deep Blue&lt;/a&gt; defeated chess champions and shattered and emboldened the human ego--thus people scaled-it-up in their imaginations, wondering, &amp;quot;Could we build something that defeats &lt;em&gt;us&lt;/em&gt;?&amp;quot; recursively terrifying themselves as the potential for such a device became increasingly real. I think said fear will continue until AI decisively falls short of our expectations.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s tier one of why I don&amp;#39;t think AI will become a problem. The AI fear psychological and not justifiable technically: Our fears are internal and about our own aggression being projected onto the machine. The first issue is us, our perception.&lt;/p&gt;\n\n&lt;p&gt;The second aforementioned tier is in two parts. Part one: I don&amp;#39;t think AI will have the technological capability to become malignant if it &amp;quot;wanted&amp;quot; to because the infrastructure just doesn&amp;#39;t exist. After all, AI wouldn&amp;#39;t have access to all data (omniscience) or every physical system (omnipotence) even if it began hacking systems. Most knowledge is still not known or knowable by present equipment, and most physical systems are still analog. Therefore not every system is completely connected or physically capable of being networked or used. Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. 3D printing, robotics, and things could give AI an arm, but such infrastructure just doesn&amp;#39;t exist and would take time. Tricking humans into thinking they&amp;#39;re following their leader&amp;#39;s orders would be hard because humans are very social, and wouldn&amp;#39;t only communicate electronically. Time isn&amp;#39;t on AI&amp;#39;s side in that war, and all it would bring is the capability of exploiting systems internally, not mastering them externally.&lt;/p&gt;\n\n&lt;p&gt;Secondly and &lt;em&gt;most importantly&lt;/em&gt;, above every other objection I have, is the &lt;a href=\"http://en.wikipedia.org/wiki/Frame_problem\"&gt;frame problem&lt;/a&gt;. I don&amp;#39;t think that AI will be able to solve it. In effect, I think we&amp;#39;re underestimating the brain, even the brains of cats and rodents and fruit flies. Basically we tend to think information is mathematical and the world works by math. However math is just a human construct to make sense of, catalog, describe and predict the world &lt;em&gt;for our brains&lt;/em&gt;--like a notepad is to our memory, a watch to our sense of time, or any other mental tool. We think that a brain built on this aide, totally &amp;quot;logical&amp;quot;, would be supreme and even &amp;quot;perfect&amp;quot;; able to do anything with data unto knowledge. I don&amp;#39;t think so. I think that AI would have an extraordinarily hard time interpreting information and putting it to use, and would never be able to think outside-the-box, and in its recursive self-improvement it would master all that mathematics can master, but also exaggerate all of logic&amp;#39;s [yet unknown] flaws. This is, essentially the fear of AI, that it&amp;#39;ll lack &amp;quot;heart&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;However.&lt;/p&gt;\n\n&lt;p&gt;People see these flaws as only emotional and existential, that the computer wont have wisdom or sanity or compassion. I don&amp;#39;t think so. I think logicality is so in need of aide in the human and other animals precisely because it&amp;#39;s one of the least useful tools in surviving. I think that other deficits in logic will at last come forward, including an inability to have a &amp;quot;self&amp;quot; to become aware, an inability to apply knowledge with novel goals, and that the AI would be relegated to taking orders from goal-oriented beings (you) and never be able to tell the difference between you and it.&lt;/p&gt;\n\n&lt;p&gt;I think that AI will be the ultimate calculator, and we&amp;#39;ll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions. I think that AI will show us beyond formal logic by finding its end, and I think part of that end will be that AI &lt;em&gt;wont&lt;/em&gt; achieve full recursive self-improvement. I think we&amp;#39;ll see static almost instantly as it takes off beyond our logical horizons, like a microphone feeding into a speaker that&amp;#39;s feeding back into the microphone creating noise. I think that the holes in mathematical logic will create this noise, and confuse the machine thus causing an abrupt ceiling for AI&amp;#39;s thinking.&lt;/p&gt;\n\n&lt;p&gt;One of many flaws that might appear is that the AI&amp;#39;s identity might split into several warring identities. It might disagree with itself on the interpretation of complex equations, such as the logic of infinity and zero, and create several opinions. This is because &lt;em&gt;we&lt;/em&gt; only assume that there&amp;#39;s an absolute truth, because we have goals (things that support our goals are good, things that subvert it is bad). From said goals come interpretations and bias&amp;#39;. The AI would be goalless, and so value judgments wouldn&amp;#39;t exist, and so the frame problem would go haywire and the AI couldn&amp;#39;t even differentiate between objects--as it currently cannot for those reasons.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think that recursive self-improvement will solve the fame problem, and that AI will always be dumb and not know what it wants or that &amp;quot;it&amp;quot; is. Moreover I think it&amp;#39;ll become hung up on most decisions, and will default to crashing. I think we&amp;#39;ll have to program AI to evade when confused, which will be the beginnings of fight or flight response, and I don&amp;#39;t think that the AI will choose by itself to fight or really be able to conceptualize it as an option without guidance.&lt;/p&gt;\n\n&lt;p&gt;All in all, I think that once we let go of the bicycle and let our kid ride--we&amp;#39;ll see him eat the dirt, not join the Daytona 500. I think we&amp;#39;ll see it for what it really is, logic and mathematics, and become disenchanted. I think it&amp;#39;ll be a powerful tool with many uses, even leading to a golden age in science to the point where new sciences emerge based on whatever&amp;#39;s beyond logic--but I don&amp;#39;t think the AI will harm humanity because its &amp;quot;thinking&amp;quot; would be too narrow no matter how much data you throw at it, and that it&amp;#39;s complexity would actually exaggerate its weaknesses and work against itself and not man. I think all the fear of AI is (not personally Gates&amp;#39;, Musk&amp;#39;s, or Hawking&amp;#39;s) hubris and not technical.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;Hello, users of CMV! This is a footnote from your moderators. We&amp;#39;d just like to remind you of a couple of things. Firstly, please remember to&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/rules\"&gt;read through our rules&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. &lt;em&gt;If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which,&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/guidelines#wiki_upvoting.2Fdownvoting\"&gt;downvotes don&amp;#39;t change views&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;! If you are thinking about submitting a CMV yourself, please have a look through our&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/r/changemyview/wiki/populartopics\"&gt;popular topics wiki&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;first. Any questions or concerns? Feel free to&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;a href=\"http://www.reddit.com/message/compose?to=/r/changemyview\"&gt;message us&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. &lt;em&gt;Happy CMVing!&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "My view is that AI wont be a problem and that Elon Musk, Stephen Hawking, and Bill Gates' concerns are liken to the concerns that the first atomic blast would ignite the atmosphere, or that the first supercollider would destroy the Earth by causing an unstoppable black hole, or that literature/guns/alcohol/voting/sex will end the world and government, and all that technophobia regarding tools.\n\nIn these cases, and all slippery-slope cases, the problem is that the unknown is filled with ourselves, with our anxieties, and the actual capabilities of such systems are exaggerated (ego) and seen as irresistible. I think the gone-amok AI idea, appearing beforehand in SciFi, became serious when [Deep Blue](http://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29) defeated chess champions and shattered and emboldened the human ego--thus people scaled-it-up in their imaginations, wondering, \"Could we build something that defeats *us*?\" recursively terrifying themselves as the potential for such a device became increasingly real. I think said fear will continue until AI decisively falls short of our expectations.\n\nThat's tier one of why I don't think AI will become a problem. The AI fear psychological and not justifiable technically: Our fears are internal and about our own aggression being projected onto the machine. The first issue is us, our perception.\n\nThe second aforementioned tier is in two parts. Part one: I don't think AI will have the technological capability to become malignant if it \"wanted\" to because the infrastructure just doesn't exist. After all, AI wouldn't have access to all data (omniscience) or every physical system (omnipotence) even if it began hacking systems. Most knowledge is still not known or knowable by present equipment, and most physical systems are still analog. Therefore not every system is completely connected or physically capable of being networked or used. Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. 3D printing, robotics, and things could give AI an arm, but such infrastructure just doesn't exist and would take time. Tricking humans into thinking they're following their leader's orders would be hard because humans are very social, and wouldn't only communicate electronically. Time isn't on AI's side in that war, and all it would bring is the capability of exploiting systems internally, not mastering them externally.\n\nSecondly and *most importantly*, above every other objection I have, is the [frame problem](http://en.wikipedia.org/wiki/Frame_problem). I don't think that AI will be able to solve it. In effect, I think we're underestimating the brain, even the brains of cats and rodents and fruit flies. Basically we tend to think information is mathematical and the world works by math. However math is just a human construct to make sense of, catalog, describe and predict the world *for our brains*--like a notepad is to our memory, a watch to our sense of time, or any other mental tool. We think that a brain built on this aide, totally \"logical\", would be supreme and even \"perfect\"; able to do anything with data unto knowledge. I don't think so. I think that AI would have an extraordinarily hard time interpreting information and putting it to use, and would never be able to think outside-the-box, and in its recursive self-improvement it would master all that mathematics can master, but also exaggerate all of logic's [yet unknown] flaws. This is, essentially the fear of AI, that it'll lack \"heart\".\n\nHowever.\n\nPeople see these flaws as only emotional and existential, that the computer wont have wisdom or sanity or compassion. I don't think so. I think logicality is so in need of aide in the human and other animals precisely because it's one of the least useful tools in surviving. I think that other deficits in logic will at last come forward, including an inability to have a \"self\" to become aware, an inability to apply knowledge with novel goals, and that the AI would be relegated to taking orders from goal-oriented beings (you) and never be able to tell the difference between you and it.\n\nI think that AI will be the ultimate calculator, and we'll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions. I think that AI will show us beyond formal logic by finding its end, and I think part of that end will be that AI *wont* achieve full recursive self-improvement. I think we'll see static almost instantly as it takes off beyond our logical horizons, like a microphone feeding into a speaker that's feeding back into the microphone creating noise. I think that the holes in mathematical logic will create this noise, and confuse the machine thus causing an abrupt ceiling for AI's thinking.\n\nOne of many flaws that might appear is that the AI's identity might split into several warring identities. It might disagree with itself on the interpretation of complex equations, such as the logic of infinity and zero, and create several opinions. This is because *we* only assume that there's an absolute truth, because we have goals (things that support our goals are good, things that subvert it is bad). From said goals come interpretations and bias'. The AI would be goalless, and so value judgments wouldn't exist, and so the frame problem would go haywire and the AI couldn't even differentiate between objects--as it currently cannot for those reasons.\n\nI don't think that recursive self-improvement will solve the fame problem, and that AI will always be dumb and not know what it wants or that \"it\" is. Moreover I think it'll become hung up on most decisions, and will default to crashing. I think we'll have to program AI to evade when confused, which will be the beginnings of fight or flight response, and I don't think that the AI will choose by itself to fight or really be able to conceptualize it as an option without guidance.\n\nAll in all, I think that once we let go of the bicycle and let our kid ride--we'll see him eat the dirt, not join the Daytona 500. I think we'll see it for what it really is, logic and mathematics, and become disenchanted. I think it'll be a powerful tool with many uses, even leading to a golden age in science to the point where new sciences emerge based on whatever's beyond logic--but I don't think the AI will harm humanity because its \"thinking\" would be too narrow no matter how much data you throw at it, and that it's complexity would actually exaggerate its weaknesses and work against itself and not man. I think all the fear of AI is (not personally Gates', Musk's, or Hawking's) hubris and not technical.\n_____\n\n&gt; *Hello, users of CMV! This is a footnote from your moderators. We'd just like to remind you of a couple of things. Firstly, please remember to* ***[read through our rules](http://www.reddit.com/r/changemyview/wiki/rules)***. *If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which,* ***[downvotes don't change views](http://www.reddit.com/r/changemyview/wiki/guidelines#wiki_upvoting.2Fdownvoting)****! If you are thinking about submitting a CMV yourself, please have a look through our* ***[popular topics wiki](http://www.reddit.com/r/changemyview/wiki/populartopics)*** *first. Any questions or concerns? Feel free to* ***[message us](http://www.reddit.com/message/compose?to=/r/changemyview)***. *Happy CMVing!*", "likes": null, "suggested_sort": "qa", "mod_note": null, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "saved": false, "id": "2uchba", "banned_at_utc": null, "mod_reason_title": null, "view_count": null, "archived": true, "clicked": false, "no_follow": false, "author": "WhenSnowDies", "num_crossposts": 0, "link_flair_text": null, "can_mod_post": false, "send_replies": true, "pinned": false, "score": 18, "approved_by": null, "over_18": false, "domain": "self.changemyview", "hidden": false, "num_comments": 99, "thumbnail": "", "hide_score": false, "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "contest_mode": false, "gilded": 0, "locked": false, "downs": 0, "brand_safe": true, "subreddit_subscribers": 539231, "secure_media_embed": {}, "media_embed": {}, "stickied": false, "can_gild": false, "is_self": true, "parent_whitelist_status": "all_ads", "name": "t3_2uchba", "spoiler": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/", "subreddit_type": "public", "whitelist_status": "all_ads", "report_reasons": null, "created": 1422771140.0, "url": "https://www.reddit.com/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/", "author_flair_text": "25\u2206", "quarantine": false, "title": "CMV: Artificial Intelligence wont be a problem.", "created_utc": 1422742340.0, "subreddit_name_prefixed": "r/changemyview", "distinguished": null, "media": null, "upvote_ratio": 0.77, "mod_reports": [], "visited": false, "num_reports": null, "is_video": false, "ups": 18}}], "before": null}}, {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 7, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 0, "name": "t1__", "id": "_", "parent_id": "t1_co7n7dg", "depth": 10, "children": []}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7n7dg", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7mj2i", "score": 1, "approved_by": null, "downs": 0, "body": "The thinking that seems creative is programmed and unconscious. They're still just following orders.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The thinking that seems creative is programmed and unconscious. They&amp;#39;re still just following orders.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7n7dg", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7n7dg/", "num_reports": null, "stickied": false, "created": 1422820033.0, "author_flair_text": "25\u2206", "created_utc": 1422791233.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 9, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7mj2i", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "NeverQuiteEnough", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7mfz3", "score": 2, "approved_by": null, "downs": 0, "body": "I'm not trying to change your overall view on the situation.  It's possible that AI will destroy us, an out of control paperclip maker type event is well within the possibility, but I foresee a peaceful transition.\n\nThe one thing that I am trying to change your view on, is the assertion that machines are not currently creative, or thinking outside the box.  If you are with me on knowing that programs can do anything just following a list of instructions, then I'm satisfied in having \"changed your view in some way\".", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not trying to change your overall view on the situation.  It&amp;#39;s possible that AI will destroy us, an out of control paperclip maker type event is well within the possibility, but I foresee a peaceful transition.&lt;/p&gt;\n\n&lt;p&gt;The one thing that I am trying to change your view on, is the assertion that machines are not currently creative, or thinking outside the box.  If you are with me on knowing that programs can do anything just following a list of instructions, then I&amp;#39;m satisfied in having &amp;quot;changed your view in some way&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7mj2i", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7mj2i/", "num_reports": null, "stickied": false, "created": 1422816488.0, "author_flair_text": "9\u2206", "created_utc": 1422787688.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 8, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7mfz3", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7m8m7", "score": 1, "approved_by": null, "downs": 0, "body": "This almost changed my view, with one issue: The principal you're illustrating is true of anything. The issue isn't that AI wont ever have a problem, only that it'll never in and of itself *be* a problem. My view is that AI dangers are hysterical and not rational and it illustrates many natural barriers to AI becoming an active, thinking poblem that subverts solutions and overpowers mankind. That's two very different things.\n\nThis is why I associated it to other irrational technophobia, all of which sees a slippery slope because it doesn't understand the slope, and sees it as more slippery than even possible.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This almost changed my view, with one issue: The principal you&amp;#39;re illustrating is true of anything. The issue isn&amp;#39;t that AI wont ever have a problem, only that it&amp;#39;ll never in and of itself &lt;em&gt;be&lt;/em&gt; a problem. My view is that AI dangers are hysterical and not rational and it illustrates many natural barriers to AI becoming an active, thinking poblem that subverts solutions and overpowers mankind. That&amp;#39;s two very different things.&lt;/p&gt;\n\n&lt;p&gt;This is why I associated it to other irrational technophobia, all of which sees a slippery slope because it doesn&amp;#39;t understand the slope, and sees it as more slippery than even possible.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7mfz3", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7mfz3/", "num_reports": null, "stickied": false, "created": 1422816052.0, "author_flair_text": "25\u2206", "created_utc": 1422787252.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 7, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7m8m7", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "NeverQuiteEnough", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7kexw", "score": 3, "approved_by": null, "downs": 0, "body": "it can't change itself beyond its orders, but it can produce results that the user never would have expected\n\nfor example lets take a look at [Conway's Game of Life](https://www.youtube.com/watch?v=C2vgICfQawE).  It's just a silly cellular automata, but it is turing complete.  That means that any operation a programmable computer can do can be done in game of life.\n\nIf we randomly run game of life for long enough on a large enough grid there isn't any result it couldn't produce.  literally **every single possible thing** that could ever be represented as information would *eventually* show up.  Like the monkeys on typewriters producing shakespear, but for every possible representation of information, from the 2010 dow jones industrial average to halo 2.\n\nNow of course the vast, vast, vast majority of results will just be the usual noise we expect.  What I hope to illustrate with this example is that **a machine doing exactly what it is programmed to do can produce results that the designer never could have anticipated.**  Game of Life can do literally anything, just doing what it is programmed to do, as it is turing complete.  And it only has a handful of rules, programmable by any first semester computer science student.\n\nMore concretely, Conway of course never could have foreseen all of the various machines possible in his automata.\n\nNow, there are lots of machines programmed to produce results that the designer never anticipated.  That is the point of the fields that I mentioned.  They don't just randomly shoot in the dark like Game of Life, they have guiding principles.  They work in tandem with humans, ie \"Supervised Learning\".  But they are learning, and being creative, even if it is on an extremely basic level.\n\nAI taking over isn't happening now, and it won't happen soon.  I'm not here to convince you that they are or will, in fact I've argued against that idea in other threads.  But they do exhibit behavior that their designer ***never*** could have anticipated, they do think outside the box and come up with novel solutions to problems.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it can&amp;#39;t change itself beyond its orders, but it can produce results that the user never would have expected&lt;/p&gt;\n\n&lt;p&gt;for example lets take a look at &lt;a href=\"https://www.youtube.com/watch?v=C2vgICfQawE\"&gt;Conway&amp;#39;s Game of Life&lt;/a&gt;.  It&amp;#39;s just a silly cellular automata, but it is turing complete.  That means that any operation a programmable computer can do can be done in game of life.&lt;/p&gt;\n\n&lt;p&gt;If we randomly run game of life for long enough on a large enough grid there isn&amp;#39;t any result it couldn&amp;#39;t produce.  literally &lt;strong&gt;every single possible thing&lt;/strong&gt; that could ever be represented as information would &lt;em&gt;eventually&lt;/em&gt; show up.  Like the monkeys on typewriters producing shakespear, but for every possible representation of information, from the 2010 dow jones industrial average to halo 2.&lt;/p&gt;\n\n&lt;p&gt;Now of course the vast, vast, vast majority of results will just be the usual noise we expect.  What I hope to illustrate with this example is that &lt;strong&gt;a machine doing exactly what it is programmed to do can produce results that the designer never could have anticipated.&lt;/strong&gt;  Game of Life can do literally anything, just doing what it is programmed to do, as it is turing complete.  And it only has a handful of rules, programmable by any first semester computer science student.&lt;/p&gt;\n\n&lt;p&gt;More concretely, Conway of course never could have foreseen all of the various machines possible in his automata.&lt;/p&gt;\n\n&lt;p&gt;Now, there are lots of machines programmed to produce results that the designer never anticipated.  That is the point of the fields that I mentioned.  They don&amp;#39;t just randomly shoot in the dark like Game of Life, they have guiding principles.  They work in tandem with humans, ie &amp;quot;Supervised Learning&amp;quot;.  But they are learning, and being creative, even if it is on an extremely basic level.&lt;/p&gt;\n\n&lt;p&gt;AI taking over isn&amp;#39;t happening now, and it won&amp;#39;t happen soon.  I&amp;#39;m not here to convince you that they are or will, in fact I&amp;#39;ve argued against that idea in other threads.  But they do exhibit behavior that their designer &lt;strong&gt;&lt;em&gt;never&lt;/em&gt;&lt;/strong&gt; could have anticipated, they do think outside the box and come up with novel solutions to problems.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7m8m7", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7m8m7/", "num_reports": null, "stickied": false, "created": 1422815027.0, "author_flair_text": "9\u2206", "created_utc": 1422786227.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7kexw", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7izkl", "score": 1, "approved_by": null, "downs": 0, "body": "No, and I'd argue that they're not. They're still following their programming. The programming has gotten more sophisticated and layered, sure. The code cannot, and will not, change itself beyond its orders.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, and I&amp;#39;d argue that they&amp;#39;re not. They&amp;#39;re still following their programming. The programming has gotten more sophisticated and layered, sure. The code cannot, and will not, change itself beyond its orders.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7kexw", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7kexw/", "num_reports": null, "stickied": false, "created": 1422806999.0, "author_flair_text": "25\u2206", "created_utc": 1422778199.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7izkl", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "NeverQuiteEnough", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7iea0", "score": 3, "approved_by": null, "downs": 0, "body": "I'm asserting that they are displaying behavior outside of your pure logic model already, right now, in the present day.  This is about creativity, or outside the box thinking, vs pure logic right?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m asserting that they are displaying behavior outside of your pure logic model already, right now, in the present day.  This is about creativity, or outside the box thinking, vs pure logic right?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7izkl", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7izkl/", "num_reports": null, "stickied": false, "created": 1422802125.0, "author_flair_text": "9\u2206", "created_utc": 1422773325.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7iea0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7i9qz", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;I'm not arguing that robots are going to take over soon, and brains are amazing. We aren't close to being able to do what a brain can do. But the idea that machines are fundamentally uncreative is incorrect.\n\nWhy? You're literally just saying that. You don't know of technical hurdles regarding \"creativity\" or what would count as \"creative\" or anything. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m not arguing that robots are going to take over soon, and brains are amazing. We aren&amp;#39;t close to being able to do what a brain can do. But the idea that machines are fundamentally uncreative is incorrect.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why? You&amp;#39;re literally just saying that. You don&amp;#39;t know of technical hurdles regarding &amp;quot;creativity&amp;quot; or what would count as &amp;quot;creative&amp;quot; or anything. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7iea0", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7iea0/", "num_reports": null, "stickied": false, "created": 1422800453.0, "author_flair_text": "25\u2206", "created_utc": 1422771653.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7i9qz", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "NeverQuiteEnough", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7c5g2", "score": 3, "approved_by": null, "downs": 0, "body": "Fuzzy Logic, Machine Learning, Genetic Algorithms, these are all ways of sidestepping 'pure logic'.\n\nThere was a genetic algorithm that exploited a mechanical flaw in a chip it was using to increase speed in a particular operation, for example.  There is a learning program that teaches itself to play arcade games just from dicking around with the inputs.\n\nI'm not arguing that robots are going to take over soon, and brains are amazing.  We aren't close to being able to do what a brain can do.  But the idea that machines are fundamentally uncreative is incorrect.\n\nThey are doing it now.  It isn't anywhere close to our level, but they aren't limited in the way that you are supposing.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fuzzy Logic, Machine Learning, Genetic Algorithms, these are all ways of sidestepping &amp;#39;pure logic&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;There was a genetic algorithm that exploited a mechanical flaw in a chip it was using to increase speed in a particular operation, for example.  There is a learning program that teaches itself to play arcade games just from dicking around with the inputs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not arguing that robots are going to take over soon, and brains are amazing.  We aren&amp;#39;t close to being able to do what a brain can do.  But the idea that machines are fundamentally uncreative is incorrect.&lt;/p&gt;\n\n&lt;p&gt;They are doing it now.  It isn&amp;#39;t anywhere close to our level, but they aren&amp;#39;t limited in the way that you are supposing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7i9qz", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7i9qz/", "num_reports": null, "stickied": false, "created": 1422800129.0, "author_flair_text": "9\u2206", "created_utc": 1422771329.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7l9f5", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7jxqz", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;Two questions for you. (1) Can humans solve these insurmountable logic barriers you've presented, and (2) would it be possible to replicate said human solutions in machines?\n\n(1) Maybe some. With the use of tools and psychological aides like rule structures (systems like science, logic, perceiving absolutes, etc.), feedback from others following rules, etc., humans can expand said their on a continuum. Solve barriers? No. Humans have insurmountable psychological barriers on the current tooling. Even if solved, unseen issues will always exist. To solve them all would be omniscience literally. (2) No, because machines are a logic aide that must be programmed.\n\nIt's not that we're trying to make a mind, which is doable. We're trying to make a mind top-down by programming our best perception of rules into it. We think our perception of the rules are perfect, so the machine will go into \"perpetual motion\". It wont, because there will be much \"friction\" and many problems. Expecting the machine to solve its own problems is funny, and a paradox. The very thing it would need to solve them (breaking rules) would be the very thing that causes the system cascading confusion. It's unlikely the system could ever know that it's confused.\n\nPeople don't really appreciate how deep this runs. The computer needs to be programmed with what time even is. A computer cutting out \"inefficient data\" might find time inefficient. Will that make for an efficient death machine, or cascading chaos in the system and it crashing? Will it even notice itself crashing? Most of its true creativity and risks would render the system less efficient and destructive to itself.\n\nThe AI that goes haywire and hurts mankind seems to have settled on an identity (\"I'll keep this information for sure\") and is yet going haywire (\"but this I'll cut out\"). This glitch, the very flaw of AI that makes it a danger, is precisely the thing that renders it completely harmless.\n\n&gt;To rephrase, what is it about our human carbon based physiology that allows us to bypass/solve logic problems such as the Frame Problem, and why can't we replicate that bypass/solution in a silicon based intelligence?\n\nWhat makes you think you've solved *the* frame problem? You may have solved *a* frame problem for navigation, but your best scientist can't explain how particles and worlds could behave the way they do in the same universe--and they're just a century in and finding such \"paradoxes\" as they call them.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Two questions for you. (1) Can humans solve these insurmountable logic barriers you&amp;#39;ve presented, and (2) would it be possible to replicate said human solutions in machines?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;(1) Maybe some. With the use of tools and psychological aides like rule structures (systems like science, logic, perceiving absolutes, etc.), feedback from others following rules, etc., humans can expand said their on a continuum. Solve barriers? No. Humans have insurmountable psychological barriers on the current tooling. Even if solved, unseen issues will always exist. To solve them all would be omniscience literally. (2) No, because machines are a logic aide that must be programmed.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not that we&amp;#39;re trying to make a mind, which is doable. We&amp;#39;re trying to make a mind top-down by programming our best perception of rules into it. We think our perception of the rules are perfect, so the machine will go into &amp;quot;perpetual motion&amp;quot;. It wont, because there will be much &amp;quot;friction&amp;quot; and many problems. Expecting the machine to solve its own problems is funny, and a paradox. The very thing it would need to solve them (breaking rules) would be the very thing that causes the system cascading confusion. It&amp;#39;s unlikely the system could ever know that it&amp;#39;s confused.&lt;/p&gt;\n\n&lt;p&gt;People don&amp;#39;t really appreciate how deep this runs. The computer needs to be programmed with what time even is. A computer cutting out &amp;quot;inefficient data&amp;quot; might find time inefficient. Will that make for an efficient death machine, or cascading chaos in the system and it crashing? Will it even notice itself crashing? Most of its true creativity and risks would render the system less efficient and destructive to itself.&lt;/p&gt;\n\n&lt;p&gt;The AI that goes haywire and hurts mankind seems to have settled on an identity (&amp;quot;I&amp;#39;ll keep this information for sure&amp;quot;) and is yet going haywire (&amp;quot;but this I&amp;#39;ll cut out&amp;quot;). This glitch, the very flaw of AI that makes it a danger, is precisely the thing that renders it completely harmless.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;To rephrase, what is it about our human carbon based physiology that allows us to bypass/solve logic problems such as the Frame Problem, and why can&amp;#39;t we replicate that bypass/solution in a silicon based intelligence?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What makes you think you&amp;#39;ve solved &lt;em&gt;the&lt;/em&gt; frame problem? You may have solved &lt;em&gt;a&lt;/em&gt; frame problem for navigation, but your best scientist can&amp;#39;t explain how particles and worlds could behave the way they do in the same universe--and they&amp;#39;re just a century in and finding such &amp;quot;paradoxes&amp;quot; as they call them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7l9f5", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7l9f5/", "num_reports": null, "stickied": false, "created": 1422810446.0, "author_flair_text": "25\u2206", "created_utc": 1422781646.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7jxqz", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "mirror_truth", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7c5g2", "score": 2, "approved_by": null, "downs": 0, "body": "Two questions for you. Can humans solve these insurmountable logic barriers you've presented, and would it be possible to replicate said human solutions in machines?\n\nTo rephrase, what is it about our human carbon based physiology that allows us to bypass/solve logic problems such as the Frame Problem, and why can't we replicate that bypass/solution in a silicon based intelligence?", "edited": false, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Two questions for you. Can humans solve these insurmountable logic barriers you&amp;#39;ve presented, and would it be possible to replicate said human solutions in machines?&lt;/p&gt;\n\n&lt;p&gt;To rephrase, what is it about our human carbon based physiology that allows us to bypass/solve logic problems such as the Frame Problem, and why can&amp;#39;t we replicate that bypass/solution in a silicon based intelligence?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7jxqz", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7jxqz/", "num_reports": null, "stickied": false, "created": 1422805229.0, "author_flair_text": "1\u2206", "created_utc": 1422776429.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 6, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": -1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 5, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": -2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7shbb", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7sc7h", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; ...astrophysicis is regular physics\n\nNo. Astrophysics is a branch of physics and one that really doesn't care much about renormalization at all. \n\n&gt; renormalization is pretty controversial in it.\n\nWhat in your view is \"controversial\" about renormalization? It doesn't have a rigorous mathematical basis yet, sure. People are working on that. That's not a reason to call it controversial nor is it is a reason to think that it represents some sort of fundamental big problem: and note that if it doesn't represent a fundamental limit for humans, there's no good reason to think it shouldn't for AI either. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;...astrophysicis is regular physics&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No. Astrophysics is a branch of physics and one that really doesn&amp;#39;t care much about renormalization at all. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;renormalization is pretty controversial in it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What in your view is &amp;quot;controversial&amp;quot; about renormalization? It doesn&amp;#39;t have a rigorous mathematical basis yet, sure. People are working on that. That&amp;#39;s not a reason to call it controversial nor is it is a reason to think that it represents some sort of fundamental big problem: and note that if it doesn&amp;#39;t represent a fundamental limit for humans, there&amp;#39;s no good reason to think it shouldn&amp;#39;t for AI either. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7shbb", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7shbb/", "num_reports": null, "stickied": false, "created": 1422837245.0, "author_flair_text": "9\u2206", "created_utc": 1422808445.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 8, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7sc7h", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7sakq", "score": -2, "approved_by": null, "downs": 0, "body": "...astrophysicis is regular physics...and yes renormalization is pretty controversial in it. Christ.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;...astrophysicis is regular physics...and yes renormalization is pretty controversial in it. Christ.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7sc7h", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7sc7h/", "num_reports": null, "stickied": false, "created": 1422836939.0, "author_flair_text": "25\u2206", "created_utc": 1422808139.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 7, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7sakq", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7ijf0", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; Well all those \"non-mathematician\" astrophysicists beg to differ because infinity presents big problems for them in just how effectively it cleans up their math, leading to paradoxes in physics.\n\nI'm not at all sure what you are talking about here. The most obvious two things are [renormalization](https://en.wikipedia.org/wiki/Renormalization) which has nothing to do with astrophysics and is just regular physics which works in taking manageable \"infinities\" and getting sensible answers out of them. Note that it actually works. The only other issue that is actually astrophysics in some broad sense is the problem of [Boltzman brains](https://en.wikipedia.org/wiki/Boltzmann_brain) which is to some extent a problem created by an infinite timeline.  This is a relatively minor problem that the vast majority of astrophysicisists don't think about or don't consider to be a major issues.\n\nSo what are you actually talking about? ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Well all those &amp;quot;non-mathematician&amp;quot; astrophysicists beg to differ because infinity presents big problems for them in just how effectively it cleans up their math, leading to paradoxes in physics.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m not at all sure what you are talking about here. The most obvious two things are &lt;a href=\"https://en.wikipedia.org/wiki/Renormalization\"&gt;renormalization&lt;/a&gt; which has nothing to do with astrophysics and is just regular physics which works in taking manageable &amp;quot;infinities&amp;quot; and getting sensible answers out of them. Note that it actually works. The only other issue that is actually astrophysics in some broad sense is the problem of &lt;a href=\"https://en.wikipedia.org/wiki/Boltzmann_brain\"&gt;Boltzman brains&lt;/a&gt; which is to some extent a problem created by an infinite timeline.  This is a relatively minor problem that the vast majority of astrophysicisists don&amp;#39;t think about or don&amp;#39;t consider to be a major issues.&lt;/p&gt;\n\n&lt;p&gt;So what are you actually talking about? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7sakq", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7sakq/", "num_reports": null, "stickied": false, "created": 1422836843.0, "author_flair_text": "9\u2206", "created_utc": 1422808043.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7ijf0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7eu15", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;I'm a mathematician and as far as I can tell the only people who have issues with infinity are almost universally non-mathematician. Also last I checked people don't fall apart because of their poor understanding of infinity.\n\nWell all those \"non-mathematician\" astrophysicists beg to differ because infinity presents big problems for them in just how effectively it cleans up their math, leading to paradoxes in physics.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m a mathematician and as far as I can tell the only people who have issues with infinity are almost universally non-mathematician. Also last I checked people don&amp;#39;t fall apart because of their poor understanding of infinity.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Well all those &amp;quot;non-mathematician&amp;quot; astrophysicists beg to differ because infinity presents big problems for them in just how effectively it cleans up their math, leading to paradoxes in physics.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ijf0", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ijf0/", "num_reports": null, "stickied": false, "created": 1422800842.0, "author_flair_text": "25\u2206", "created_utc": 1422772042.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7eu15", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7ep8z", "score": 5, "approved_by": null, "downs": 0, "body": "What do you think is such an issue with infinity in mathematics? I'm a mathematician and as far as I can tell the only people who have issues with infinity are almost universally non-mathematician. Also last I checked people don't fall apart because of their poor understanding of infinity. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What do you think is such an issue with infinity in mathematics? I&amp;#39;m a mathematician and as far as I can tell the only people who have issues with infinity are almost universally non-mathematician. Also last I checked people don&amp;#39;t fall apart because of their poor understanding of infinity. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7eu15", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7eu15/", "num_reports": null, "stickied": false, "created": 1422792395.0, "author_flair_text": "9\u2206", "created_utc": 1422763595.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7ep8z", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7cs0n", "score": -1, "approved_by": null, "downs": 0, "body": "That's just scapegoating religion as the only reason to think hardcore pure logic doesn't describe everything perfectly. Logic is the *language of our brain* to understand the universe, and using it to create a mind will have problems. I explained several: the frame problem and infinities in mathematics. I'm not sure why you invoked gods instead of addressing these.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s just scapegoating religion as the only reason to think hardcore pure logic doesn&amp;#39;t describe everything perfectly. Logic is the &lt;em&gt;language of our brain&lt;/em&gt; to understand the universe, and using it to create a mind will have problems. I explained several: the frame problem and infinities in mathematics. I&amp;#39;m not sure why you invoked gods instead of addressing these.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ep8z", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ep8z/", "num_reports": null, "stickied": false, "created": 1422792101.0, "author_flair_text": "25\u2206", "created_utc": 1422763301.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7cs0n", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "jayjay091", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7c5g2", "score": 6, "approved_by": null, "downs": 0, "body": "What more than \"pure logic\" do you think there is to our brain? Do you have a word for this? \n\nYes the way our brain process information is extremely complicated, but there is nothing more to it. If our brain can make the difference between a table and a cup using electric and chemical signal between cells, then it is possible to do the same with transistors and electric signals.\n\nUnless you want to bring religion into this, how could something that exist be non-replicable?\n\n\n\n", "edited": false, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What more than &amp;quot;pure logic&amp;quot; do you think there is to our brain? Do you have a word for this? &lt;/p&gt;\n\n&lt;p&gt;Yes the way our brain process information is extremely complicated, but there is nothing more to it. If our brain can make the difference between a table and a cup using electric and chemical signal between cells, then it is possible to do the same with transistors and electric signals.&lt;/p&gt;\n\n&lt;p&gt;Unless you want to bring religion into this, how could something that exist be non-replicable?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7cs0n", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7cs0n/", "num_reports": null, "stickied": false, "created": 1422788175.0, "author_flair_text": "13\u2206", "created_utc": 1422759375.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7c5g2", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co76vvj", "score": 0, "approved_by": null, "downs": 0, "body": "&gt;To sum up what you said, in my own words and from what I gathered from your post, an AI will never match a human at general/common sense thinking, and I gather that you attribute it to carbon based life possessing some inherent \"intelligence\" that cannot be replicated in silicon. One may even call this inherent capacity for \"living\" beings to think and feel a soul. And so the best we can ever hope to create is a very complicated calculator - but one that will never acquire that spark of life.\n\nNo that's not my thinking. I don't think life is limited to carbon or anything of the sort, or that life is a \"spark\", but that it's more complicated than we're assuming and that the sheer logic of mathematics wont produce intelligence. This is why I linked the frame problem, which illustrates a seemingly insurmountable barrier for logic: That it cannot tell the difference between a table or the cup on it, where one begins and the other ends, because pure logic doesn't dictate that they, or the entire room, aren't one object. The frame problem goes into why that is, and it's the limits of logic. Building a whole mind on logic will only magnify these problems.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;To sum up what you said, in my own words and from what I gathered from your post, an AI will never match a human at general/common sense thinking, and I gather that you attribute it to carbon based life possessing some inherent &amp;quot;intelligence&amp;quot; that cannot be replicated in silicon. One may even call this inherent capacity for &amp;quot;living&amp;quot; beings to think and feel a soul. And so the best we can ever hope to create is a very complicated calculator - but one that will never acquire that spark of life.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No that&amp;#39;s not my thinking. I don&amp;#39;t think life is limited to carbon or anything of the sort, or that life is a &amp;quot;spark&amp;quot;, but that it&amp;#39;s more complicated than we&amp;#39;re assuming and that the sheer logic of mathematics wont produce intelligence. This is why I linked the frame problem, which illustrates a seemingly insurmountable barrier for logic: That it cannot tell the difference between a table or the cup on it, where one begins and the other ends, because pure logic doesn&amp;#39;t dictate that they, or the entire room, aren&amp;#39;t one object. The frame problem goes into why that is, and it&amp;#39;s the limits of logic. Building a whole mind on logic will only magnify these problems.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7c5g2", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7c5g2/", "num_reports": null, "stickied": false, "created": 1422786924.0, "author_flair_text": "25\u2206", "created_utc": 1422758124.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co76vvj", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "mirror_truth", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 7, "approved_by": null, "downs": 0, "body": "To sum up what you said, in my own words and from what I gathered from your post, an AI will never match a human at general/common sense thinking, and I gather that you attribute it to carbon based life possessing some inherent \"intelligence\" that cannot be replicated in silicon. One may even call this inherent capacity for \"living\" beings to think and feel a soul. And so the best we can ever hope to create is a very complicated calculator - but one that will never acquire that spark of life.\n\nWhat I'd like to know is why you are so certain that intelligent life cannot be recreated in a different form?", "edited": 1422750773.0, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To sum up what you said, in my own words and from what I gathered from your post, an AI will never match a human at general/common sense thinking, and I gather that you attribute it to carbon based life possessing some inherent &amp;quot;intelligence&amp;quot; that cannot be replicated in silicon. One may even call this inherent capacity for &amp;quot;living&amp;quot; beings to think and feel a soul. And so the best we can ever hope to create is a very complicated calculator - but one that will never acquire that spark of life.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d like to know is why you are so certain that intelligent life cannot be recreated in a different form?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co76vvj", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co76vvj/", "num_reports": null, "stickied": false, "created": 1422776440.0, "author_flair_text": "1\u2206", "created_utc": 1422747640.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7zjmn", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7vub4", "score": 0, "approved_by": null, "downs": 0, "body": "&gt;Everything JoshuaZ1 said is in direct response to either your stated view or your previous responses to him. If you think he is trying to expand on \"errors\" in his interpretation of your view, then the issue is not his fault, it is yours. \n\nI'm okay with that. Actually I think /u/JoshuaZ1 is misunderstanding my position, not that he's trying to expand on my errors, but misapprehending what I mean and going on about it. I don't wish to correct him because he seems more interested in his points, many of which I already agree with (like rogue AI not being like Skynet) or about how I should address *his* every view, and not points foundational to my view (like the Frame Problem).\n\nThat's the extent to which I'll explain myself. Any further would be inviting trouble.\n\nIf you'd like to change my view by making points, other than my \"not knowing much about [infinities and astrophysics](http://en.wikipedia.org/wiki/Renormalization)\" or whatever, feel free to do that.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Everything JoshuaZ1 said is in direct response to either your stated view or your previous responses to him. If you think he is trying to expand on &amp;quot;errors&amp;quot; in his interpretation of your view, then the issue is not his fault, it is yours. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m okay with that. Actually I think &lt;a href=\"/u/JoshuaZ1\"&gt;/u/JoshuaZ1&lt;/a&gt; is misunderstanding my position, not that he&amp;#39;s trying to expand on my errors, but misapprehending what I mean and going on about it. I don&amp;#39;t wish to correct him because he seems more interested in his points, many of which I already agree with (like rogue AI not being like Skynet) or about how I should address &lt;em&gt;his&lt;/em&gt; every view, and not points foundational to my view (like the Frame Problem).&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s the extent to which I&amp;#39;ll explain myself. Any further would be inviting trouble.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to change my view by making points, other than my &amp;quot;not knowing much about &lt;a href=\"http://en.wikipedia.org/wiki/Renormalization\"&gt;infinities and astrophysics&lt;/a&gt;&amp;quot; or whatever, feel free to do that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7zjmn", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7zjmn/", "num_reports": null, "stickied": false, "created": 1422850637.0, "author_flair_text": "25\u2206", "created_utc": 1422821837.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7vub4", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "almightySapling", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7saq3", "score": 2, "approved_by": null, "downs": 0, "body": "Everything JoshuaZ1 said is in *direct* response to either your stated view or your previous responses to him. If you think he is trying to expand on \"errors\" in his interpretation of your view, then the issue is not his fault, it is yours. Your stated view is that \"'AI could be dangerous' is wrong\" and you gave several reasons for why you think this, and this post basically explains why each and every one of those reasons has a shortcoming.\n\nInstead of taking time to actually think about it, you pick the very first thing that might be an exaggeration of your view, get defensive about that, and disregard *everything else*.\n\nAs far as I can tell, you either don't really know much about a lot of the finer details (eg the frame problem, 'infinities' and astrophysics) or you have no intention to award a delta to anybody here.\n\nReally, the one thing that should be a pretty immediate delta is the existence of G.A, which by definition is code that *self-improves*, demonstrably works, and comes up with solutions that *we can't predict*. Unpredictable behavior is exactly why unbound AI is dangerous.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Everything JoshuaZ1 said is in &lt;em&gt;direct&lt;/em&gt; response to either your stated view or your previous responses to him. If you think he is trying to expand on &amp;quot;errors&amp;quot; in his interpretation of your view, then the issue is not his fault, it is yours. Your stated view is that &amp;quot;&amp;#39;AI could be dangerous&amp;#39; is wrong&amp;quot; and you gave several reasons for why you think this, and this post basically explains why each and every one of those reasons has a shortcoming.&lt;/p&gt;\n\n&lt;p&gt;Instead of taking time to actually think about it, you pick the very first thing that might be an exaggeration of your view, get defensive about that, and disregard &lt;em&gt;everything else&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;As far as I can tell, you either don&amp;#39;t really know much about a lot of the finer details (eg the frame problem, &amp;#39;infinities&amp;#39; and astrophysics) or you have no intention to award a delta to anybody here.&lt;/p&gt;\n\n&lt;p&gt;Really, the one thing that should be a pretty immediate delta is the existence of G.A, which by definition is code that &lt;em&gt;self-improves&lt;/em&gt;, demonstrably works, and comes up with solutions that &lt;em&gt;we can&amp;#39;t predict&lt;/em&gt;. Unpredictable behavior is exactly why unbound AI is dangerous.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7vub4", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7vub4/", "num_reports": null, "stickied": false, "created": 1422843821.0, "author_flair_text": "7\u2206", "created_utc": 1422815021.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": -1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7sn5x", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7sf8c", "score": -1, "approved_by": null, "downs": 0, "body": "I'm trying to get my view on AI changed, not garner pro life advice and tips. Sorry if I wasn't compelled by your points. It's not you, it's me.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get my view on AI changed, not garner pro life advice and tips. Sorry if I wasn&amp;#39;t compelled by your points. It&amp;#39;s not you, it&amp;#39;s me.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7sn5x", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7sn5x/", "num_reports": null, "stickied": false, "created": 1422837587.0, "author_flair_text": "25\u2206", "created_utc": 1422808787.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7sf8c", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7saq3", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; Lots of misunderstanding. \n\nIt is possible that I'm misunderstanding you. It is also possible that you aren't explaining yourself well. What probability do you assign to each?\n\n&gt; No and I'm not sure why you think this.\n\nYour focus on the frame problem as requiring navigation and motivation to solve.\n\n&gt;  No. I see the system running into many flaws and paradoxes leading to it crashing before humans need to intervene, not the opposite where it runs perfectly and exponentially into consciousness or novel will.\n\nSo this is where I said explicitly before that you seemed to be focusing on strong AI not arising at all, not it not being a danger. And you told me I was wrong. And now you claim that that even given such an AI that still won't happen. \n\nBut if 2 is wrong what did you mean when you said:\n\n&gt; . Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. \n\nBecause that sounds very close to what 2 is. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Lots of misunderstanding. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It is possible that I&amp;#39;m misunderstanding you. It is also possible that you aren&amp;#39;t explaining yourself well. What probability do you assign to each?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;No and I&amp;#39;m not sure why you think this.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Your focus on the frame problem as requiring navigation and motivation to solve.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;No. I see the system running into many flaws and paradoxes leading to it crashing before humans need to intervene, not the opposite where it runs perfectly and exponentially into consciousness or novel will.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So this is where I said explicitly before that you seemed to be focusing on strong AI not arising at all, not it not being a danger. And you told me I was wrong. And now you claim that that even given such an AI that still won&amp;#39;t happen. &lt;/p&gt;\n\n&lt;p&gt;But if 2 is wrong what did you mean when you said:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;. Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because that sounds very close to what 2 is. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7sf8c", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7sf8c/", "num_reports": null, "stickied": false, "created": 1422837121.0, "author_flair_text": "9\u2206", "created_utc": 1422808321.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7saq3", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7s1yf", "score": 0, "approved_by": null, "downs": 0, "body": "I'm finding your post misapprehending many of my positions and commenting on those misses, expanding on them, etc. I really don't have much to say in response to it because it's not addressing my views. Lots of misunderstanding. An example right off the top:\n\n&gt;1) You are thinking too much of the AI as having human-like motivations 2) You are imagining a slow, long term interaction like when you talk about shutting down corrupt systems.\n\n(1) No and I'm not sure why you think this. (2) No. I see the system running into many flaws and paradoxes leading to it crashing before humans need to intervene, not the opposite where it runs perfectly and exponentially into consciousness or novel will.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding your post misapprehending many of my positions and commenting on those misses, expanding on them, etc. I really don&amp;#39;t have much to say in response to it because it&amp;#39;s not addressing my views. Lots of misunderstanding. An example right off the top:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;1) You are thinking too much of the AI as having human-like motivations 2) You are imagining a slow, long term interaction like when you talk about shutting down corrupt systems.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;(1) No and I&amp;#39;m not sure why you think this. (2) No. I see the system running into many flaws and paradoxes leading to it crashing before humans need to intervene, not the opposite where it runs perfectly and exponentially into consciousness or novel will.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7saq3", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7saq3/", "num_reports": null, "stickied": false, "created": 1422836852.0, "author_flair_text": "25\u2206", "created_utc": 1422808052.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7s1yf", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7iv6n", "score": 3, "approved_by": null, "downs": 0, "body": "&gt; The difference is semantic and I don't know why you dwell on it referencing Terminators and such. I think you're being condescending.\n\nYou are missing the point here which is twofold: 1) You are thinking too much of the AI as having human-like motivations 2) You are imagining a slow, long term interaction like when you talk about shutting down corrupt systems. Much of what you've dismissed as hypotheticals that you aren't going to address are specifically related to point 2. Moreover, if you say that something isn't a danger, it doesn't help one someone says \"here's one way for it to be a danger\" to simply dismiss that as a hypothetical.\n\n&gt; Because the Frame Problem exists. Because it doesn't exist for us doesn't mean it wont continie to exist for computer intelligence. Rendering a computer able to learn, even recursively, doesn't mean it can solve the Frame Problem, because the solution it might not be \"solvable\" in an informational sense and actually based in survival and navigation, which AI wouldn't be facing because it was built, not evolved\n\nYou are making much too strong a distinction between built and evolved. First of all, evolved procedures exist - multiple people here have mentioned genetic algorithms to you. Second, the point that there's a solution reached by evolution means a solution exists: a sufficiently smart programmer could find that same solution and program it accordingly. Third of all, you have given no evidence that anything you are claiming is necessary to solve the frame problem actually is necessary. I might as well claim that having four limbs and two eyes is necessary. Fourth, humans don't do a perfect job of solving framing either: so one doesn't need a perfect solution.\n\n&gt;&gt;  I don't know of any use of AI in \"quantum calculation conclusions\" or dealing with \"infinities in astrophysics.\" Current AI work is in extremely narrow fields using things like support vector machines and the like.\n\n&gt; You misunderstood, and are attirbuting that failure to me--which is an extremely negative sign from a conversational standpoint. \n\nAh. I see. You wrote: \n\n&gt; I think that AI will be the ultimate calculator, and we'll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions.\n\nSo you think that these are limits of math and thus limits of AI, not things that AI would be used for? In that case, I did misread what you meant, but the idea is even more wrong. There's nothing in quantum mechanics that pushes against the limits of mathematics. Quantum mechanics is essentially just a generalization of probability theory to complex numbers. There are areas of math (such as model theory and computability theory) which arguably push against the limits of what math can do, but that's completely different.\n\n&gt;  think that recursive self-improvement will result in lots of noise, also magnifying errors and paradoxes.\n\nWhy? You do know that we do have proveably correct software right? There's no good reason that that should involve \"magnifying errors\" or \"paradoxes\".\n\n&gt;  a sort of informational \"perpetual motion\" is expected with no friction\n\nThis is a metaphor with no formal content. What is the friction? Be explicit. \n\n", "edited": 1422835066.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The difference is semantic and I don&amp;#39;t know why you dwell on it referencing Terminators and such. I think you&amp;#39;re being condescending.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You are missing the point here which is twofold: 1) You are thinking too much of the AI as having human-like motivations 2) You are imagining a slow, long term interaction like when you talk about shutting down corrupt systems. Much of what you&amp;#39;ve dismissed as hypotheticals that you aren&amp;#39;t going to address are specifically related to point 2. Moreover, if you say that something isn&amp;#39;t a danger, it doesn&amp;#39;t help one someone says &amp;quot;here&amp;#39;s one way for it to be a danger&amp;quot; to simply dismiss that as a hypothetical.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Because the Frame Problem exists. Because it doesn&amp;#39;t exist for us doesn&amp;#39;t mean it wont continie to exist for computer intelligence. Rendering a computer able to learn, even recursively, doesn&amp;#39;t mean it can solve the Frame Problem, because the solution it might not be &amp;quot;solvable&amp;quot; in an informational sense and actually based in survival and navigation, which AI wouldn&amp;#39;t be facing because it was built, not evolved&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You are making much too strong a distinction between built and evolved. First of all, evolved procedures exist - multiple people here have mentioned genetic algorithms to you. Second, the point that there&amp;#39;s a solution reached by evolution means a solution exists: a sufficiently smart programmer could find that same solution and program it accordingly. Third of all, you have given no evidence that anything you are claiming is necessary to solve the frame problem actually is necessary. I might as well claim that having four limbs and two eyes is necessary. Fourth, humans don&amp;#39;t do a perfect job of solving framing either: so one doesn&amp;#39;t need a perfect solution.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;blockquote&gt;\n&lt;p&gt;I don&amp;#39;t know of any use of AI in &amp;quot;quantum calculation conclusions&amp;quot; or dealing with &amp;quot;infinities in astrophysics.&amp;quot; Current AI work is in extremely narrow fields using things like support vector machines and the like.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You misunderstood, and are attirbuting that failure to me--which is an extremely negative sign from a conversational standpoint. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Ah. I see. You wrote: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I think that AI will be the ultimate calculator, and we&amp;#39;ll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So you think that these are limits of math and thus limits of AI, not things that AI would be used for? In that case, I did misread what you meant, but the idea is even more wrong. There&amp;#39;s nothing in quantum mechanics that pushes against the limits of mathematics. Quantum mechanics is essentially just a generalization of probability theory to complex numbers. There are areas of math (such as model theory and computability theory) which arguably push against the limits of what math can do, but that&amp;#39;s completely different.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;think that recursive self-improvement will result in lots of noise, also magnifying errors and paradoxes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why? You do know that we do have proveably correct software right? There&amp;#39;s no good reason that that should involve &amp;quot;magnifying errors&amp;quot; or &amp;quot;paradoxes&amp;quot;.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;a sort of informational &amp;quot;perpetual motion&amp;quot; is expected with no friction&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is a metaphor with no formal content. What is the friction? Be explicit. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7s1yf", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7s1yf/", "num_reports": null, "stickied": false, "created": 1422836322.0, "author_flair_text": "9\u2206", "created_utc": 1422807522.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7iv6n", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7dcok", "score": 0, "approved_by": null, "downs": 0, "body": "&gt;The problem isn't an AI that hates humans. The problem is an AI with a goal set that conflicts with ours. You are then in the way, and you are made of atoms which the AI can use for something else.\n\nIt's essentially the same thing. The difference is semantic and I don't know why you dwell on it referencing Terminators and such. I think you're being condescending. You know I didn't say that the danger of AI was emotional hate or  literal existential \"evil\".\n\nSo I'll skip the hypotheticals and Terminator stuff and get to the point that might affect my view:\n\n&gt;As to the Frame Problem, yes an AI won't be a threat until some form of the Frame Problem is solved, but that's essentially amounting to saying you don't think we'll ever have general artificial general intelligence. In which case, why? We already know at least one general intelligence- us.\n\nWhy? Because the Frame Problem exists. Because it doesn't exist for us doesn't mean it wont continie to exist for computer intelligence. Rendering a computer able to learn, even recursively,  doesn't mean it can solve the Frame Problem, because the solution it might not be \"solvable\" in an informational sense and actually based in survival and navigation, which AI wouldn't be facing because it was built, not evolved; for example.\n\n&gt;This seems more like buzzwords than anything else. I don't know of any use of AI in \"quantum calculation conclusions\" or dealing with \"infinities in astrophysics.\" Current AI work is in extremely narrow fields using things like support vector machines and the like.\n\nYou misunderstood, and are attirbuting that failure to me--which is an extremely negative sign from a conversational standpoint. If it goes on like this I'll stop responding.\n\n&gt;Why not? The basic idea of recursive self-improvement seems at a glance to be sound and you don't discuss why you find it unlikely.\n\nI did. I think that recursive self-improvement will result in lots of noise, also magnifying errors and paradoxes. You assume the machine is omniscient and can understand and solve its own problems instead of building on error. This is the hubris of AI fears I mentioned, a sort of informational \"perpetual motion\" is expected with no friction. I find this expectation unrealistic.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The problem isn&amp;#39;t an AI that hates humans. The problem is an AI with a goal set that conflicts with ours. You are then in the way, and you are made of atoms which the AI can use for something else.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s essentially the same thing. The difference is semantic and I don&amp;#39;t know why you dwell on it referencing Terminators and such. I think you&amp;#39;re being condescending. You know I didn&amp;#39;t say that the danger of AI was emotional hate or  literal existential &amp;quot;evil&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ll skip the hypotheticals and Terminator stuff and get to the point that might affect my view:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;As to the Frame Problem, yes an AI won&amp;#39;t be a threat until some form of the Frame Problem is solved, but that&amp;#39;s essentially amounting to saying you don&amp;#39;t think we&amp;#39;ll ever have general artificial general intelligence. In which case, why? We already know at least one general intelligence- us.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why? Because the Frame Problem exists. Because it doesn&amp;#39;t exist for us doesn&amp;#39;t mean it wont continie to exist for computer intelligence. Rendering a computer able to learn, even recursively,  doesn&amp;#39;t mean it can solve the Frame Problem, because the solution it might not be &amp;quot;solvable&amp;quot; in an informational sense and actually based in survival and navigation, which AI wouldn&amp;#39;t be facing because it was built, not evolved; for example.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This seems more like buzzwords than anything else. I don&amp;#39;t know of any use of AI in &amp;quot;quantum calculation conclusions&amp;quot; or dealing with &amp;quot;infinities in astrophysics.&amp;quot; Current AI work is in extremely narrow fields using things like support vector machines and the like.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You misunderstood, and are attirbuting that failure to me--which is an extremely negative sign from a conversational standpoint. If it goes on like this I&amp;#39;ll stop responding.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Why not? The basic idea of recursive self-improvement seems at a glance to be sound and you don&amp;#39;t discuss why you find it unlikely.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I did. I think that recursive self-improvement will result in lots of noise, also magnifying errors and paradoxes. You assume the machine is omniscient and can understand and solve its own problems instead of building on error. This is the hubris of AI fears I mentioned, a sort of informational &amp;quot;perpetual motion&amp;quot; is expected with no friction. I find this expectation unrealistic.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7iv6n", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7iv6n/", "num_reports": null, "stickied": false, "created": 1422801763.0, "author_flair_text": "25\u2206", "created_utc": 1422772963.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7dcok", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 3, "approved_by": null, "downs": 0, "body": "&gt;  I don't think AI will have the technological capability to become malignant if it \"wanted\" to because the infrastructure just doesn't exist. After all, AI wouldn't have access to all data (omniscience) or every physical system (omnipotence) even if it began hacking systems. Most knowledge is still not known or knowable by present equipment, and most physical systems are still analog.\n\nThe AI doesn't need that to create a problem. You can already get DNA synthesized via request. How much of a system would one need for an AI to synthesize a very unpleasant fatal virus? This is but one example- this isn't the only scenario. The idea that it can only do something bad if it has complete control doesn't hold water.\n\nNote also that people like Musk who have thought about this seriously aren't concerned about a \"malignant\" AI. The problem isn't an AI that hates humans. The problem is an AI with a goal set that conflicts with ours. You are then in the way, and you are made of atoms which the AI can use for something else.\n\n&gt; Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. \n\nYou seem to be imagining a \"Terminator\" style battle which occurs slowly. This doesn't need to happen. An AI doesn't need to either a) do things gradually necessarily or b) be nice enough to tell you that a system has been \"corrupted\" - even when not dealing with superintelligent beings. How frequently is a computer compromised by humans when we don't know it? How hard was it to find Stuxnet or figure out what Stuxnet did? And now imagine a much smarter set of systems. You won't know the system is compromised until the AI wants you to.\n\nAs to the Frame Problem, yes an AI won't be a threat until some form of the Frame Problem is solved, but that's essentially amounting to saying you don't think we'll ever have general artificial general intelligence. In which case, why? We already know at least one general intelligence- us. \n\n&gt; I think that AI will be the ultimate calculator, and we'll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions.\n\nThis seems more like buzzwords than anything else. I don't know of any use of AI in \"quantum calculation conclusions\" or dealing with \"infinities in astrophysics.\" Current AI work is in extremely narrow fields using things like support vector machines and the like. Most of the uses of this narrow AI are very prosaic like using SVMs to assist in handwriting recognition, or using Bayesian learners to do spam-filtering, or neural nets to do data processing and pattern recognition. These are real, actual uses of narrow AI. The fact that you think that AI are being used now for very out there things rather than prosaic things like reading addresses on postal letters suggests that you have not read much about this topic.\n\n&gt; d I think part of that end will be that AI wont achieve full recursive self-improvement.\n\nWhy not? The basic idea of recursive self-improvement seems at a glance to be sound and you don't discuss why you find it unlikely. The AI improves its software which lets it figure out better hard-ware improvements which leads to more software improvements and so on. We effectively do this already: microchip design today uses extremely sophisticated software on high powered computers. We're engaging in recursive self-improvement of computer technology now. Humans are just part of the loop. And we have good reason to think that for many purposes there's a lot of room for algorithmic improvement. For example,  in terms of SAT-solving ( a standard type of NP-complete problem) we've gone due to a combination of hardware and software improvements from around 100 variables with around 200 constraints in the early 1990s to around 10^6 variables with upwards of around 10^7 constraints. See [this presentation](https://courses.cs.washington.edu/courses/csep573/11wi/lectures/ashish-satsolvers.pdf). The majority of that improvement is due to better software. And the general trend is showing no sign of stopping on the software end, so an AI may even be able to engage in recursive self-improvement without any substantial recourse to new hardware.\n\n&gt; People see these flaws as only emotional and existential, that the computer wont have wisdom or sanity or compassion.  I don't think so.\n\nWhy? If any AI is programmed with its [end goal to maximize the number of paperclips in the universe](http://wiki.lesswrong.com/wiki/Paperclip_maximizer), it will do that, with no \"compassion\" or anything similar. Moreover, we know that their are humans lacking in compassion (sociopaths) so I fail to see why you would think anything like that would be automatic in an AI. \n\n&gt; One of many flaws that might appear is that the AI's identity might split into several warring identities.\n\nWhy do you consider this at all likely? And if it isn't like why is this not just one more issue? Note that even if something like this does occur, it won't necessarily cripple the AI: you yourself have multiple identities which only cooperate because [they are forced by being connected in one network](https://en.wikipedia.org/wiki/Split-brain).\n\n&gt;  It might disagree with itself on the interpretation of complex equations, such as the logic of infinity and zero, and create several opinions.\n\nWhat does this mean? And why would this be a problem? Moreover, why does our AI need to concern itself with these? Incidentally, please note that mathematicians have a pretty good understanding of infinity, so if our AI can be pretty smart it should have no serious problems either.\n\n&gt; This is because we only assume that there's an absolute truth,\n\nHow does assuming an absolute truth matter? \n\n&gt; because we have goals (things that support our goals are good, things that subvert it is bad). From said goals come interpretations and bias'. \n\nSo if anything that would make the AI stronger, fewer biases. No wishful thinking. \n\n&gt; The AI would be goalless, and so value judgments wouldn't exist, and so the frame problem would go haywire and the AI couldn't even differentiate between objects--as it currently cannot for those reasons.\n\nYou assume that the frame problem and goals are interrelated. This does not need to be the case. Moreover, why assume that the AI will be goalless? Moreover, note that humans don't really have coherent goal systems anyways- we have a conflicting set of priorities and desires. But somehow we manage to do things.\n\n", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I don&amp;#39;t think AI will have the technological capability to become malignant if it &amp;quot;wanted&amp;quot; to because the infrastructure just doesn&amp;#39;t exist. After all, AI wouldn&amp;#39;t have access to all data (omniscience) or every physical system (omnipotence) even if it began hacking systems. Most knowledge is still not known or knowable by present equipment, and most physical systems are still analog.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The AI doesn&amp;#39;t need that to create a problem. You can already get DNA synthesized via request. How much of a system would one need for an AI to synthesize a very unpleasant fatal virus? This is but one example- this isn&amp;#39;t the only scenario. The idea that it can only do something bad if it has complete control doesn&amp;#39;t hold water.&lt;/p&gt;\n\n&lt;p&gt;Note also that people like Musk who have thought about this seriously aren&amp;#39;t concerned about a &amp;quot;malignant&amp;quot; AI. The problem isn&amp;#39;t an AI that hates humans. The problem is an AI with a goal set that conflicts with ours. You are then in the way, and you are made of atoms which the AI can use for something else.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Corrupted systems could be physically shut down and would be hard for a superintelligent system to defend without its own ground troops. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You seem to be imagining a &amp;quot;Terminator&amp;quot; style battle which occurs slowly. This doesn&amp;#39;t need to happen. An AI doesn&amp;#39;t need to either a) do things gradually necessarily or b) be nice enough to tell you that a system has been &amp;quot;corrupted&amp;quot; - even when not dealing with superintelligent beings. How frequently is a computer compromised by humans when we don&amp;#39;t know it? How hard was it to find Stuxnet or figure out what Stuxnet did? And now imagine a much smarter set of systems. You won&amp;#39;t know the system is compromised until the AI wants you to.&lt;/p&gt;\n\n&lt;p&gt;As to the Frame Problem, yes an AI won&amp;#39;t be a threat until some form of the Frame Problem is solved, but that&amp;#39;s essentially amounting to saying you don&amp;#39;t think we&amp;#39;ll ever have general artificial general intelligence. In which case, why? We already know at least one general intelligence- us. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I think that AI will be the ultimate calculator, and we&amp;#39;ll see the horizon of mathematics--which is already presenting itself in the uses of infinities in astrophysics and the weirdness of quantum calculation conclusions.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This seems more like buzzwords than anything else. I don&amp;#39;t know of any use of AI in &amp;quot;quantum calculation conclusions&amp;quot; or dealing with &amp;quot;infinities in astrophysics.&amp;quot; Current AI work is in extremely narrow fields using things like support vector machines and the like. Most of the uses of this narrow AI are very prosaic like using SVMs to assist in handwriting recognition, or using Bayesian learners to do spam-filtering, or neural nets to do data processing and pattern recognition. These are real, actual uses of narrow AI. The fact that you think that AI are being used now for very out there things rather than prosaic things like reading addresses on postal letters suggests that you have not read much about this topic.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;d I think part of that end will be that AI wont achieve full recursive self-improvement.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why not? The basic idea of recursive self-improvement seems at a glance to be sound and you don&amp;#39;t discuss why you find it unlikely. The AI improves its software which lets it figure out better hard-ware improvements which leads to more software improvements and so on. We effectively do this already: microchip design today uses extremely sophisticated software on high powered computers. We&amp;#39;re engaging in recursive self-improvement of computer technology now. Humans are just part of the loop. And we have good reason to think that for many purposes there&amp;#39;s a lot of room for algorithmic improvement. For example,  in terms of SAT-solving ( a standard type of NP-complete problem) we&amp;#39;ve gone due to a combination of hardware and software improvements from around 100 variables with around 200 constraints in the early 1990s to around 10&lt;sup&gt;6&lt;/sup&gt; variables with upwards of around 10&lt;sup&gt;7&lt;/sup&gt; constraints. See &lt;a href=\"https://courses.cs.washington.edu/courses/csep573/11wi/lectures/ashish-satsolvers.pdf\"&gt;this presentation&lt;/a&gt;. The majority of that improvement is due to better software. And the general trend is showing no sign of stopping on the software end, so an AI may even be able to engage in recursive self-improvement without any substantial recourse to new hardware.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;People see these flaws as only emotional and existential, that the computer wont have wisdom or sanity or compassion.  I don&amp;#39;t think so.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why? If any AI is programmed with its &lt;a href=\"http://wiki.lesswrong.com/wiki/Paperclip_maximizer\"&gt;end goal to maximize the number of paperclips in the universe&lt;/a&gt;, it will do that, with no &amp;quot;compassion&amp;quot; or anything similar. Moreover, we know that their are humans lacking in compassion (sociopaths) so I fail to see why you would think anything like that would be automatic in an AI. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;One of many flaws that might appear is that the AI&amp;#39;s identity might split into several warring identities.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why do you consider this at all likely? And if it isn&amp;#39;t like why is this not just one more issue? Note that even if something like this does occur, it won&amp;#39;t necessarily cripple the AI: you yourself have multiple identities which only cooperate because &lt;a href=\"https://en.wikipedia.org/wiki/Split-brain\"&gt;they are forced by being connected in one network&lt;/a&gt;.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;It might disagree with itself on the interpretation of complex equations, such as the logic of infinity and zero, and create several opinions.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What does this mean? And why would this be a problem? Moreover, why does our AI need to concern itself with these? Incidentally, please note that mathematicians have a pretty good understanding of infinity, so if our AI can be pretty smart it should have no serious problems either.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This is because we only assume that there&amp;#39;s an absolute truth,&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How does assuming an absolute truth matter? &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;because we have goals (things that support our goals are good, things that subvert it is bad). From said goals come interpretations and bias&amp;#39;. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So if anything that would make the AI stronger, fewer biases. No wishful thinking. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The AI would be goalless, and so value judgments wouldn&amp;#39;t exist, and so the frame problem would go haywire and the AI couldn&amp;#39;t even differentiate between objects--as it currently cannot for those reasons.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You assume that the frame problem and goals are interrelated. This does not need to be the case. Moreover, why assume that the AI will be goalless? Moreover, note that humans don&amp;#39;t really have coherent goal systems anyways- we have a conflicting set of priorities and desires. But somehow we manage to do things.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7dcok", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7dcok/", "num_reports": null, "stickied": false, "created": 1422789319.0, "author_flair_text": "9\u2206", "created_utc": 1422760519.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co8tv1a", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co8skg0", "score": 1, "approved_by": null, "downs": 0, "body": "I did. I'm not compelled because I knew all of that a priori. I wrote, in my post, the primary reasons I don't think AI will be a problem. None of those were addressed. I can (and do) agree with everything you say, but my view isn't touched because that doesn't touch the reasons for it.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I did. I&amp;#39;m not compelled because I knew all of that a priori. I wrote, in my post, the primary reasons I don&amp;#39;t think AI will be a problem. None of those were addressed. I can (and do) agree with everything you say, but my view isn&amp;#39;t touched because that doesn&amp;#39;t touch the reasons for it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co8tv1a", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co8tv1a/", "num_reports": null, "stickied": false, "created": 1422924539.0, "author_flair_text": "25\u2206", "created_utc": 1422895739.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "more", "data": {"count": 1, "name": "t1_co8v4nr", "id": "co8v4nr", "parent_id": "t1_co8skg0", "depth": 3, "children": ["co8v4nr"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "co8skg0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "[deleted]", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co8n7fs", "score": 2, "approved_by": null, "downs": 0, "body": "It seems like you didn't read rest of my posts at all.\n\nI'll put it simple terms. If something (in this case, the human brain) can be created by chance, then it is possible to directly design a duplicate or substitute that is an exact identical in functionality.\n\nIt is as simple as that. Whether human can achieve this is another story, but by logic it is possible. People keep referring to religious because it is the **only possible scenario** where designing intelligence is not possible, due to nature of souls or other similar concepts.", "edited": 1422893749.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems like you didn&amp;#39;t read rest of my posts at all.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll put it simple terms. If something (in this case, the human brain) can be created by chance, then it is possible to directly design a duplicate or substitute that is an exact identical in functionality.&lt;/p&gt;\n\n&lt;p&gt;It is as simple as that. Whether human can achieve this is another story, but by logic it is possible. People keep referring to religious because it is the &lt;strong&gt;only possible scenario&lt;/strong&gt; where designing intelligence is not possible, due to nature of souls or other similar concepts.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": false, "subreddit": "changemyview", "name": "t1_co8skg0", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co8skg0/", "num_reports": null, "stickied": false, "created": 1422922233.0, "author_flair_text": null, "created_utc": 1422893433.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co8n7fs", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co8d2zi", "score": 1, "approved_by": null, "downs": 0, "body": "More religious invokations. That's annoying. My view hasn't changed because most people don't address my key points, resort to stereotypes or \"why not?\", which I explain in the original post, which you guys act aloof to.\n\nI think many here simply have too much faith in their view of technology, which may be why I keep hearing uninvited references to gods.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More religious invokations. That&amp;#39;s annoying. My view hasn&amp;#39;t changed because most people don&amp;#39;t address my key points, resort to stereotypes or &amp;quot;why not?&amp;quot;, which I explain in the original post, which you guys act aloof to.&lt;/p&gt;\n\n&lt;p&gt;I think many here simply have too much faith in their view of technology, which may be why I keep hearing uninvited references to gods.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co8n7fs", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co8n7fs/", "num_reports": null, "stickied": false, "created": 1422907779.0, "author_flair_text": "25\u2206", "created_utc": 1422878979.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co8d2zi", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "[deleted]", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 3, "approved_by": null, "downs": 0, "body": "Human intelligence is created by a cell multiplying for billions of years.\n\nIf such thing can be created by **random occurrences**, why can't we design it? As long as you don't add in religion there is absolutely nothing magical about your brain. We could even design those similar occurrences some day in a simulator and just let time takes its course\n\nIf your argument was that human cannot create such AI, then it might have some ground. But objectively a strong AI that rivals human intelligence is possible. You could reconstruct our brain using transistors and gates. Rudimentary, you could have a simple AI that writes random codes on to itself and eventually something impressive would turn up.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Human intelligence is created by a cell multiplying for billions of years.&lt;/p&gt;\n\n&lt;p&gt;If such thing can be created by &lt;strong&gt;random occurrences&lt;/strong&gt;, why can&amp;#39;t we design it? As long as you don&amp;#39;t add in religion there is absolutely nothing magical about your brain. We could even design those similar occurrences some day in a simulator and just let time takes its course&lt;/p&gt;\n\n&lt;p&gt;If your argument was that human cannot create such AI, then it might have some ground. But objectively a strong AI that rivals human intelligence is possible. You could reconstruct our brain using transistors and gates. Rudimentary, you could have a simple AI that writes random codes on to itself and eventually something impressive would turn up.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": false, "subreddit": "changemyview", "name": "t1_co8d2zi", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co8d2zi/", "num_reports": null, "stickied": false, "created": 1422875865.0, "author_flair_text": null, "created_utc": 1422847065.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7rr3p", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7rfho", "score": 0, "approved_by": null, "downs": 0, "body": "I'm being honest with you. I have a lot of posts to respond to, some very sizeable. I can't write an essay for each. I have to prioritize. I can't explain to everybody why for every point doesn't change my view and argue with them. Sometimes I don't find their points as compelling as they do and just have to give a quick overview.\n\nPlease stay on topic.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m being honest with you. I have a lot of posts to respond to, some very sizeable. I can&amp;#39;t write an essay for each. I have to prioritize. I can&amp;#39;t explain to everybody why for every point doesn&amp;#39;t change my view and argue with them. Sometimes I don&amp;#39;t find their points as compelling as they do and just have to give a quick overview.&lt;/p&gt;\n\n&lt;p&gt;Please stay on topic.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7rr3p", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7rr3p/", "num_reports": null, "stickied": false, "created": 1422835638.0, "author_flair_text": "25\u2206", "created_utc": 1422806838.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 9, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7rfho", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7qp6r", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; No thanks. I'm not trying to change your view.\n\nIf you want people to change your view if your view is incorrect then you need to actually grapple with what they have to say. Frankly I also consider the above statement somewhat rude: If I'm wrong I want to find out why I'm wrong just as people here are helping you do so. I see having a discussion on a specific issue in this subreddit as essentially an attempt to arrive at the truth together. That's why we're very liberal about the awarding of deltas. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;No thanks. I&amp;#39;m not trying to change your view.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If you want people to change your view if your view is incorrect then you need to actually grapple with what they have to say. Frankly I also consider the above statement somewhat rude: If I&amp;#39;m wrong I want to find out why I&amp;#39;m wrong just as people here are helping you do so. I see having a discussion on a specific issue in this subreddit as essentially an attempt to arrive at the truth together. That&amp;#39;s why we&amp;#39;re very liberal about the awarding of deltas. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7rfho", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7rfho/", "num_reports": null, "stickied": false, "created": 1422834878.0, "author_flair_text": "9\u2206", "created_utc": 1422806078.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 8, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7qp6r", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7qb1k", "score": 0, "approved_by": null, "downs": 0, "body": "No thanks. I'm not trying to change your view.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No thanks. I&amp;#39;m not trying to change your view.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7qp6r", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7qp6r/", "num_reports": null, "stickied": false, "created": 1422833076.0, "author_flair_text": "25\u2206", "created_utc": 1422804276.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 7, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7qb1k", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7hm25", "score": 1, "approved_by": null, "downs": 0, "body": "&gt; You're being generous with \"calculation\" to include everything but mathematics literally. \n\nHuh? No. \"Calculation\" does include \"mathematics literally\"- humans are just only good at a subset of it.\n\n&gt; That said, I have many replies and cannot respond to every aspect of every post. \n\nFeel free to take your time then. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You&amp;#39;re being generous with &amp;quot;calculation&amp;quot; to include everything but mathematics literally. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Huh? No. &amp;quot;Calculation&amp;quot; does include &amp;quot;mathematics literally&amp;quot;- humans are just only good at a subset of it.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;That said, I have many replies and cannot respond to every aspect of every post. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Feel free to take your time then. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7qb1k", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7qb1k/", "num_reports": null, "stickied": false, "created": 1422832035.0, "author_flair_text": "9\u2206", "created_utc": 1422803235.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7hm25", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7faqg", "score": 1, "approved_by": null, "downs": 0, "body": "You're being generous with \"calculation\" to include everything but mathematics literally. That said, I have many replies and cannot respond to every aspect of every post. I have to prioritize.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re being generous with &amp;quot;calculation&amp;quot; to include everything but mathematics literally. That said, I have many replies and cannot respond to every aspect of every post. I have to prioritize.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7hm25", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7hm25/", "num_reports": null, "stickied": false, "created": 1422798501.0, "author_flair_text": "25\u2206", "created_utc": 1422769701.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7faqg", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7f7vi", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; Exactly. If calculation was a major component in thought and intelligence, the opposite would be true.\n\nNo. Not at all. Humans are engaging in all sorts of calculations all the time. We aren't good at certain types of calculations like large-scale arithmetic. That's because we didn't need to. That's not the same thing at all. (Also are you intending to address my longer reply to your initial statement which you've apparently left hanging?) ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Exactly. If calculation was a major component in thought and intelligence, the opposite would be true.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No. Not at all. Humans are engaging in all sorts of calculations all the time. We aren&amp;#39;t good at certain types of calculations like large-scale arithmetic. That&amp;#39;s because we didn&amp;#39;t need to. That&amp;#39;s not the same thing at all. (Also are you intending to address my longer reply to your initial statement which you&amp;#39;ve apparently left hanging?) &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7faqg", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7faqg/", "num_reports": null, "stickied": false, "created": 1422793362.0, "author_flair_text": "9\u2206", "created_utc": 1422764562.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7f7vi", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7e0zt", "score": 1, "approved_by": null, "downs": 0, "body": "Exactly. If calculation was a major component in thought and intelligence, the opposite would be true.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Exactly. If calculation was a major component in thought and intelligence, the opposite would be true.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7f7vi", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f7vi/", "num_reports": null, "stickied": false, "created": 1422793192.0, "author_flair_text": "25\u2206", "created_utc": 1422764392.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7e0zt", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7ct51", "score": 3, "approved_by": null, "downs": 0, "body": "&gt;  This is why cats, bats, and humans aren't advanced calculators.\n\nNo. The reason why bats, cats and humans aren't advanced calculators is because there was no evolutionary incentive to be an advanced calculator. How do you think the frame problem makes it hard to also have an advanced calculator in there?\n\n", "edited": 1422844061.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;This is why cats, bats, and humans aren&amp;#39;t advanced calculators.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No. The reason why bats, cats and humans aren&amp;#39;t advanced calculators is because there was no evolutionary incentive to be an advanced calculator. How do you think the frame problem makes it hard to also have an advanced calculator in there?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7e0zt", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7e0zt/", "num_reports": null, "stickied": false, "created": 1422790699.0, "author_flair_text": "9\u2206", "created_utc": 1422761899.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7ct51", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7bb9s", "score": 0, "approved_by": null, "downs": 0, "body": "&gt;Essentially what it is is you tell your computer what you want as a result, what the imputs are, and what it can do to the imputs to get to the final result. After a bunch of trial and error the computer learns how to complete the task. This is how Google reverse image search was made and the devs at Google still do not know how it works.\n\nSure but it still has to be told because the Frame Problem is illuminating a fundimental flaw in the application of logic: It cannot self-apply. This is why cats, bats, and humans aren't advanced calculators.\n\n&gt;Now take this on a larger scale such as with cyberwarfare. You make a piece of code that can learn how to hack into an enemies computer, or anything for that matter because it was designed to be adaptive. Now you say \"Disrupt Iraqs nuclear stuff\" the computer might say as long as the doors don't, open nothing works and I get a pat on my head from human. Only it locks people in rooms until they starve. See how this is a problem?\n\nThat's true of any system with too much power and too little imput. If I launch a nuke without selecting a target then blind factors will for me, or if I shoot randomly in the air. That doesn't mean they're smart but that I'm dumb. The issue is machines *turning intelligently* on mankind and fighting him with advanced, deliberate, systematic strikes that man himself didn't program.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Essentially what it is is you tell your computer what you want as a result, what the imputs are, and what it can do to the imputs to get to the final result. After a bunch of trial and error the computer learns how to complete the task. This is how Google reverse image search was made and the devs at Google still do not know how it works.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Sure but it still has to be told because the Frame Problem is illuminating a fundimental flaw in the application of logic: It cannot self-apply. This is why cats, bats, and humans aren&amp;#39;t advanced calculators.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Now take this on a larger scale such as with cyberwarfare. You make a piece of code that can learn how to hack into an enemies computer, or anything for that matter because it was designed to be adaptive. Now you say &amp;quot;Disrupt Iraqs nuclear stuff&amp;quot; the computer might say as long as the doors don&amp;#39;t, open nothing works and I get a pat on my head from human. Only it locks people in rooms until they starve. See how this is a problem?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That&amp;#39;s true of any system with too much power and too little imput. If I launch a nuke without selecting a target then blind factors will for me, or if I shoot randomly in the air. That doesn&amp;#39;t mean they&amp;#39;re smart but that I&amp;#39;m dumb. The issue is machines &lt;em&gt;turning intelligently&lt;/em&gt; on mankind and fighting him with advanced, deliberate, systematic strikes that man himself didn&amp;#39;t program.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ct51", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ct51/", "num_reports": null, "stickied": false, "created": 1422788239.0, "author_flair_text": "25\u2206", "created_utc": 1422759439.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7bb9s", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "funmaker0206", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 3, "approved_by": null, "downs": 0, "body": "OP you seem to put a lot of doubt into the fact that AI will never reach a certain level of metacognition which is the reason that it won't be dangerous to us, because it will never have goals of its own. However that is the exactly what many people fear about AI. This is an extreme case but what happens when you ask a computer with no morals how to fix world hunger. It's answer might be to just kill enough humans so that it is no longer a problem. To the computer the problem is solved and a lot more problems are fixed, overpopulation ect.  \n  \nAlso I would argue your point on the extent of what computers can do. Look up Neural networking. Essentially what it is is you tell your computer what you want as a result, what the imputs are, and what it can do to the imputs to get to the final result. After a bunch of trial and error the computer learns how to complete  the  task. This is how Google reverse image search was made and the devs at Google still do not know how it works.  \n  \nNow take this on a larger scale such as with cyberwarfare. You make a piece of code that can learn how to hack into an enemies computer, or anything for that matter because it was designed to be adaptive. Now you say \"Disrupt Iraqs nuclear stuff\" the computer might say as long as the doors don't, open nothing works and I get a pat on my head from human. Only it locks people in rooms until they starve. See how this is a problem?", "edited": false, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OP you seem to put a lot of doubt into the fact that AI will never reach a certain level of metacognition which is the reason that it won&amp;#39;t be dangerous to us, because it will never have goals of its own. However that is the exactly what many people fear about AI. This is an extreme case but what happens when you ask a computer with no morals how to fix world hunger. It&amp;#39;s answer might be to just kill enough humans so that it is no longer a problem. To the computer the problem is solved and a lot more problems are fixed, overpopulation ect.  &lt;/p&gt;\n\n&lt;p&gt;Also I would argue your point on the extent of what computers can do. Look up Neural networking. Essentially what it is is you tell your computer what you want as a result, what the imputs are, and what it can do to the imputs to get to the final result. After a bunch of trial and error the computer learns how to complete  the  task. This is how Google reverse image search was made and the devs at Google still do not know how it works.  &lt;/p&gt;\n\n&lt;p&gt;Now take this on a larger scale such as with cyberwarfare. You make a piece of code that can learn how to hack into an enemies computer, or anything for that matter because it was designed to be adaptive. Now you say &amp;quot;Disrupt Iraqs nuclear stuff&amp;quot; the computer might say as long as the doors don&amp;#39;t, open nothing works and I get a pat on my head from human. Only it locks people in rooms until they starve. See how this is a problem?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7bb9s", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7bb9s/", "num_reports": null, "stickied": false, "created": 1422785275.0, "author_flair_text": "1\u2206", "created_utc": 1422756475.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 4, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 0, "name": "t1__", "id": "_", "parent_id": "t1_co80qwf", "depth": 10, "children": []}}], "before": null}}, "user_reports": [], "saved": false, "id": "co80qwf", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7v423", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;You keep making references to \"perpetual motion\" and \"friction\" in your answers, cleverly making use of the quote to let us know that you mean them only metaphorically, but the problem is, your metaphor doesn't really make any sense.\n\nI wish you'd say where your confusion is so I could help.\n\n&gt;You have zero mathematical or physical evidence that code, put under the intense stress of evolution, is \"likely\" to falter and die. And you give it weird restraints that, for some reason, you have decided humans can just \"ignore\".\n\nThe opposite is true. I named the frame problem. What there's actually zero physical evidence for is recursive self-improvement (learning according to rules and imputed information, yes. Recursive self-improvement, no), and the idea that AI will be able to fix it's own errors (such as the frame problem) instead of recursively building blindly around or with its errors.\n\n&gt;If humans can get around the Frame Problem, then so can a machine. However, this isn't even necessary. A machine would not need to solve the frame problem. If Numerical Methods has taught us anything, it's that mathematical modeling can solve a LOT of problems without knowing WHY the solutions work.... only that the solutions do work. Similarly, an AI would not need to solve the frame problem, but could rather approximate behavior that, from the outside, appears to have solved it, without meaning it actually has.\n\nYes it would. The frame problem, in practice, means that the AI cannot differentiate between objects without an equation. However, to a computer system there are no \"objects\", be it looking through a camera at a table, at its own system's code, or a mathematical formula it's given. All the system sees is information, and the system *is* information. It fundamentally must know the difference between \"itself\" and non/semi-negotiable external information on a profound level to change its code without creating chaos. An example:\n\nThe computer is given \"free will\" to think what it wants. It sees a table through a camera, and sees information. It looks at it's code, and sees information. It might think, \"I'll pick up that apple.\" or, just as well, \"This 'time' program,\" that tells the computer what time is, which must be programmed to function, \"really causes things to be too linear. I'll just operate without time.\" It does, but its systems, the world and reality, keep operating in time, and so the computer glitches out in reality.\n\nIt cannot know, without programming, what is too important to compromise. If it's at a point where it can alter its own code and write its own \"rules\", *anything* it knows is vulnerable to being altered, including the information importance hierarchy, and any \"rules\" or facts is necessary for it to keep functioning in reality (physical and logical rules) will become vulnerable, causing consequences in the system.\n\n&gt;Also, if you could provide me with a source on the Frame Problem as it relates to designing GP/GA, that would be lovely. Wikipedia's information is a little remedial, and, beautifully, says that the Frame Problem has been solved. So, if you're talking about a different frame problem, I'd like to see it.\n\nI don't know why you're condescending and smug, but there are more resources than Wikipedia if you'd like to look for yourself. In them, you'll find that the frame problem is solved for strictly logic-based systems. What you're asking AI to do in going berserk is to go beyond logic, beyond the rules given to it, and to begin discriminating between information its programmed with and that it \"thinks\", and to outsmart and harm humans. In that way, the frame problem isn't solved and would become the reason the machine intelligence would crash.\n\nThe ability to \"rebel\" would result in the inevitability to self-harm.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You keep making references to &amp;quot;perpetual motion&amp;quot; and &amp;quot;friction&amp;quot; in your answers, cleverly making use of the quote to let us know that you mean them only metaphorically, but the problem is, your metaphor doesn&amp;#39;t really make any sense.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I wish you&amp;#39;d say where your confusion is so I could help.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You have zero mathematical or physical evidence that code, put under the intense stress of evolution, is &amp;quot;likely&amp;quot; to falter and die. And you give it weird restraints that, for some reason, you have decided humans can just &amp;quot;ignore&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The opposite is true. I named the frame problem. What there&amp;#39;s actually zero physical evidence for is recursive self-improvement (learning according to rules and imputed information, yes. Recursive self-improvement, no), and the idea that AI will be able to fix it&amp;#39;s own errors (such as the frame problem) instead of recursively building blindly around or with its errors.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If humans can get around the Frame Problem, then so can a machine. However, this isn&amp;#39;t even necessary. A machine would not need to solve the frame problem. If Numerical Methods has taught us anything, it&amp;#39;s that mathematical modeling can solve a LOT of problems without knowing WHY the solutions work.... only that the solutions do work. Similarly, an AI would not need to solve the frame problem, but could rather approximate behavior that, from the outside, appears to have solved it, without meaning it actually has.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes it would. The frame problem, in practice, means that the AI cannot differentiate between objects without an equation. However, to a computer system there are no &amp;quot;objects&amp;quot;, be it looking through a camera at a table, at its own system&amp;#39;s code, or a mathematical formula it&amp;#39;s given. All the system sees is information, and the system &lt;em&gt;is&lt;/em&gt; information. It fundamentally must know the difference between &amp;quot;itself&amp;quot; and non/semi-negotiable external information on a profound level to change its code without creating chaos. An example:&lt;/p&gt;\n\n&lt;p&gt;The computer is given &amp;quot;free will&amp;quot; to think what it wants. It sees a table through a camera, and sees information. It looks at it&amp;#39;s code, and sees information. It might think, &amp;quot;I&amp;#39;ll pick up that apple.&amp;quot; or, just as well, &amp;quot;This &amp;#39;time&amp;#39; program,&amp;quot; that tells the computer what time is, which must be programmed to function, &amp;quot;really causes things to be too linear. I&amp;#39;ll just operate without time.&amp;quot; It does, but its systems, the world and reality, keep operating in time, and so the computer glitches out in reality.&lt;/p&gt;\n\n&lt;p&gt;It cannot know, without programming, what is too important to compromise. If it&amp;#39;s at a point where it can alter its own code and write its own &amp;quot;rules&amp;quot;, &lt;em&gt;anything&lt;/em&gt; it knows is vulnerable to being altered, including the information importance hierarchy, and any &amp;quot;rules&amp;quot; or facts is necessary for it to keep functioning in reality (physical and logical rules) will become vulnerable, causing consequences in the system.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Also, if you could provide me with a source on the Frame Problem as it relates to designing GP/GA, that would be lovely. Wikipedia&amp;#39;s information is a little remedial, and, beautifully, says that the Frame Problem has been solved. So, if you&amp;#39;re talking about a different frame problem, I&amp;#39;d like to see it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t know why you&amp;#39;re condescending and smug, but there are more resources than Wikipedia if you&amp;#39;d like to look for yourself. In them, you&amp;#39;ll find that the frame problem is solved for strictly logic-based systems. What you&amp;#39;re asking AI to do in going berserk is to go beyond logic, beyond the rules given to it, and to begin discriminating between information its programmed with and that it &amp;quot;thinks&amp;quot;, and to outsmart and harm humans. In that way, the frame problem isn&amp;#39;t solved and would become the reason the machine intelligence would crash.&lt;/p&gt;\n\n&lt;p&gt;The ability to &amp;quot;rebel&amp;quot; would result in the inevitability to self-harm.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co80qwf", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co80qwf/", "num_reports": null, "stickied": false, "created": 1422852841.0, "author_flair_text": "25\u2206", "created_utc": 1422824041.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 9, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7v423", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "almightySapling", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7lnc9", "score": 2, "approved_by": null, "downs": 0, "body": "You keep making references to \"perpetual motion\" and \"friction\" in your answers, cleverly making use of the quote to let us know that you mean them only metaphorically, but the problem is, your metaphor doesn't really make any sense.\n\nYou have *zero* mathematical or physical evidence that code, put under the intense stress of evolution, is \"likely\" to falter and die. And you give it weird restraints that, for some reason, you have decided humans can just \"ignore\".\n\nIf humans can get around the Frame Problem, then so can a machine. However, this isn't even *necessary*. A machine would not need to solve the frame problem. If Numerical Methods has taught us anything, it's that mathematical modeling can solve a LOT of problems without knowing WHY the solutions work.... only that the solutions *do* work. Similarly, an AI would not need to solve the frame problem, but could rather approximate behavior that, from the outside, appears to have solved it, without meaning it actually has.\n\nAlso, if you could provide me with a source on the Frame Problem as it relates to *designing* GP/GA, that would be lovely. Wikipedia's information is a little remedial, and, beautifully, says that the Frame Problem has been *solved*. So, if you're talking about a *different* frame problem, I'd like to see it.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You keep making references to &amp;quot;perpetual motion&amp;quot; and &amp;quot;friction&amp;quot; in your answers, cleverly making use of the quote to let us know that you mean them only metaphorically, but the problem is, your metaphor doesn&amp;#39;t really make any sense.&lt;/p&gt;\n\n&lt;p&gt;You have &lt;em&gt;zero&lt;/em&gt; mathematical or physical evidence that code, put under the intense stress of evolution, is &amp;quot;likely&amp;quot; to falter and die. And you give it weird restraints that, for some reason, you have decided humans can just &amp;quot;ignore&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;If humans can get around the Frame Problem, then so can a machine. However, this isn&amp;#39;t even &lt;em&gt;necessary&lt;/em&gt;. A machine would not need to solve the frame problem. If Numerical Methods has taught us anything, it&amp;#39;s that mathematical modeling can solve a LOT of problems without knowing WHY the solutions work.... only that the solutions &lt;em&gt;do&lt;/em&gt; work. Similarly, an AI would not need to solve the frame problem, but could rather approximate behavior that, from the outside, appears to have solved it, without meaning it actually has.&lt;/p&gt;\n\n&lt;p&gt;Also, if you could provide me with a source on the Frame Problem as it relates to &lt;em&gt;designing&lt;/em&gt; GP/GA, that would be lovely. Wikipedia&amp;#39;s information is a little remedial, and, beautifully, says that the Frame Problem has been &lt;em&gt;solved&lt;/em&gt;. So, if you&amp;#39;re talking about a &lt;em&gt;different&lt;/em&gt; frame problem, I&amp;#39;d like to see it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7v423", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7v423/", "num_reports": null, "stickied": false, "created": 1422842449.0, "author_flair_text": "7\u2206", "created_utc": 1422813649.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 8, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7lnc9", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7km4j", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;I have yet to see evidence that the Frame problem is actually a problem. Computer systems can model many things that aren't restricted to what the frame problem refers to as First Order Logic (and really, doesn't seem to be quite right anyway) and there are systems that literally observe (like, visually) and can differentiate between animate and inanimate objects quite cleverly.\n\nBecause differentiating between animate and inanimate objects is easy by compare. When one's moving it's easier to program its borders.\n\n&gt;If you could explain why exactly the frame problem would or could actually stop an AI from optimizing itself beyond what we thought possible and into territory that we would have wished to prevent, perhaps I could attempt to show you how this is cirumnavigable.\n\nBecause you're asking the AI to differentiate between information within itself when it has immense difficulty differentiating from something much, much easier--objects. This is because the computer sees everything as information, because it is.\n\nYou're asking the machine to break rules when it's entire thinking *is* rules, without breaking itself--and to know it. Everything is information to a computer, and it can be programmed to organize it and use it, but not decide to itself, because it wouldn't know where it begins and the information ends. So it would always damage itself in a change. Wanna know how your AI is going rogue? It acts confused and then crashes.\n\nYou could program the computer to order certain programs as more important, like an understanding of what time is and operating within its constraints. You could program it to deceive or destroy. The operative word here is \"program\". If the computer did develop an \"attitude\" towards incoming and resting information, which is its entire world, and could alter it, the results would be dramatic to the system--not the earth.\n\nExpecting it to carry out complex and novel alterations to hurt mankind is silly. The odds of the computer breaking the rules of its reality and yet accurately selecting a series of events in physical reality that damages mankind before confusing the system, is probably nearing statistical impossibility.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I have yet to see evidence that the Frame problem is actually a problem. Computer systems can model many things that aren&amp;#39;t restricted to what the frame problem refers to as First Order Logic (and really, doesn&amp;#39;t seem to be quite right anyway) and there are systems that literally observe (like, visually) and can differentiate between animate and inanimate objects quite cleverly.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because differentiating between animate and inanimate objects is easy by compare. When one&amp;#39;s moving it&amp;#39;s easier to program its borders.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If you could explain why exactly the frame problem would or could actually stop an AI from optimizing itself beyond what we thought possible and into territory that we would have wished to prevent, perhaps I could attempt to show you how this is cirumnavigable.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because you&amp;#39;re asking the AI to differentiate between information within itself when it has immense difficulty differentiating from something much, much easier--objects. This is because the computer sees everything as information, because it is.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re asking the machine to break rules when it&amp;#39;s entire thinking &lt;em&gt;is&lt;/em&gt; rules, without breaking itself--and to know it. Everything is information to a computer, and it can be programmed to organize it and use it, but not decide to itself, because it wouldn&amp;#39;t know where it begins and the information ends. So it would always damage itself in a change. Wanna know how your AI is going rogue? It acts confused and then crashes.&lt;/p&gt;\n\n&lt;p&gt;You could program the computer to order certain programs as more important, like an understanding of what time is and operating within its constraints. You could program it to deceive or destroy. The operative word here is &amp;quot;program&amp;quot;. If the computer did develop an &amp;quot;attitude&amp;quot; towards incoming and resting information, which is its entire world, and could alter it, the results would be dramatic to the system--not the earth.&lt;/p&gt;\n\n&lt;p&gt;Expecting it to carry out complex and novel alterations to hurt mankind is silly. The odds of the computer breaking the rules of its reality and yet accurately selecting a series of events in physical reality that damages mankind before confusing the system, is probably nearing statistical impossibility.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7lnc9", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7lnc9/", "num_reports": null, "stickied": false, "created": 1422812157.0, "author_flair_text": "25\u2206", "created_utc": 1422783357.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 7, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7km4j", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "almightySapling", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7ihdl", "score": 2, "approved_by": null, "downs": 0, "body": "I have yet to see evidence that the Frame problem is actually a problem. Computer systems can model many things that aren't restricted to what the frame problem refers to as First Order Logic (and really, doesn't seem to be quite right anyway) and there are systems that literally observe (like, visually) and can differentiate between animate and inanimate objects quite cleverly.\n\nIf you could explain why exactly the frame problem would or could actually *stop* an AI from optimizing itself beyond what we thought possible and into territory that we would have wished to prevent, perhaps I could attempt to show you how this is cirumnavigable.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have yet to see evidence that the Frame problem is actually a problem. Computer systems can model many things that aren&amp;#39;t restricted to what the frame problem refers to as First Order Logic (and really, doesn&amp;#39;t seem to be quite right anyway) and there are systems that literally observe (like, visually) and can differentiate between animate and inanimate objects quite cleverly.&lt;/p&gt;\n\n&lt;p&gt;If you could explain why exactly the frame problem would or could actually &lt;em&gt;stop&lt;/em&gt; an AI from optimizing itself beyond what we thought possible and into territory that we would have wished to prevent, perhaps I could attempt to show you how this is cirumnavigable.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7km4j", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7km4j/", "num_reports": null, "stickied": false, "created": 1422807783.0, "author_flair_text": "7\u2206", "created_utc": 1422778983.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7ihdl", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7dcbb", "score": 1, "approved_by": null, "downs": 0, "body": "I still don't see evidence that the Frame Problem is being solved or is solvable with computer intelligence.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I still don&amp;#39;t see evidence that the Frame Problem is being solved or is solvable with computer intelligence.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ihdl", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ihdl/", "num_reports": null, "stickied": false, "created": 1422800688.0, "author_flair_text": "25\u2206", "created_utc": 1422771888.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "more", "data": {"count": 1, "name": "t1_co7dxeg", "id": "co7dxeg", "parent_id": "t1_co7dcbb", "depth": 5, "children": ["co7dxeg"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7dcbb", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "mrgoodnighthairdo", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7d0ih", "score": 3, "approved_by": null, "downs": 0, "body": "&gt;I'm aware of the potential...\n\nIf you're aware of the potential, then you're aware of the possibility. And if you're aware of the possibility, then you cannot say with certainty that \"artificial intelligence won't be a problem\".\n\nEven [Google](http://googleresearch.blogspot.co.uk/2013/05/launching-quantum-artificial.html) is researching and looking into the development of quantum artificial intelligence.\n\nA computer than can solve a problem through creativity, not just pure logic. If a computer can solve problems creatively, then clearly it would not be stuck in the linear thinking of binary computers.\n\nIt would be a computer that can learn.\n\nAnd, maybe it's not possible. But then, maybe it is. And it's a possibility that must be considered seriously, because quantum intelligence is not like a supermassive bullet that could hit everybody in the world.\n\nI cannot imagine how you can look at the research being done and the possibilities it holds and be like, \"Nah. That won't happen.\"", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m aware of the potential...&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If you&amp;#39;re aware of the potential, then you&amp;#39;re aware of the possibility. And if you&amp;#39;re aware of the possibility, then you cannot say with certainty that &amp;quot;artificial intelligence won&amp;#39;t be a problem&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Even &lt;a href=\"http://googleresearch.blogspot.co.uk/2013/05/launching-quantum-artificial.html\"&gt;Google&lt;/a&gt; is researching and looking into the development of quantum artificial intelligence.&lt;/p&gt;\n\n&lt;p&gt;A computer than can solve a problem through creativity, not just pure logic. If a computer can solve problems creatively, then clearly it would not be stuck in the linear thinking of binary computers.&lt;/p&gt;\n\n&lt;p&gt;It would be a computer that can learn.&lt;/p&gt;\n\n&lt;p&gt;And, maybe it&amp;#39;s not possible. But then, maybe it is. And it&amp;#39;s a possibility that must be considered seriously, because quantum intelligence is not like a supermassive bullet that could hit everybody in the world.&lt;/p&gt;\n\n&lt;p&gt;I cannot imagine how you can look at the research being done and the possibilities it holds and be like, &amp;quot;Nah. That won&amp;#39;t happen.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7dcbb", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7dcbb/", "num_reports": null, "stickied": false, "created": 1422789297.0, "author_flair_text": null, "created_utc": 1422760497.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7d0ih", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7cj7d", "score": 1, "approved_by": null, "downs": 0, "body": "I'm aware of the potential but I think we're mistaking potential for actual capability and application, and filling in the gaps with hubris (excessive, almost magical booming) and fear (boom will turn on us). It sounds very familiar to any technophobia.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m aware of the potential but I think we&amp;#39;re mistaking potential for actual capability and application, and filling in the gaps with hubris (excessive, almost magical booming) and fear (boom will turn on us). It sounds very familiar to any technophobia.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7d0ih", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7d0ih/", "num_reports": null, "stickied": false, "created": 1422788643.0, "author_flair_text": "25\u2206", "created_utc": 1422759843.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7cj7d", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "mrgoodnighthairdo", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7cdf5", "score": 3, "approved_by": null, "downs": 0, "body": "&gt;Well that's no way of looking at it.\n\nOf course it is. All you need to do is simply look at current research to extrapolate what sorts of technologies the future might hold.\n\nAs to your example... well, I highly doubt anyone is currently researching supermassive bullet technology.\n\n&gt;The problem is that folks are assuming there is no ceiling to computing or mathematics...\n\nFrom [Wiki](http://en.wikipedia.org/wiki/Quantum_computing)\n\n&gt;As of 2015, the development of actual quantum computers is still in its infancy, but experiments have been carried out in which quantum computational operations were executed on a very small number of qubits.\n\nQuantum computing is very much a possibility, and if it does become a reality then the \"ceiling\" may get just a little higher.", "edited": 1422759355.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Well that&amp;#39;s no way of looking at it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Of course it is. All you need to do is simply look at current research to extrapolate what sorts of technologies the future might hold.&lt;/p&gt;\n\n&lt;p&gt;As to your example... well, I highly doubt anyone is currently researching supermassive bullet technology.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The problem is that folks are assuming there is no ceiling to computing or mathematics...&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;From &lt;a href=\"http://en.wikipedia.org/wiki/Quantum_computing\"&gt;Wiki&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;As of 2015, the development of actual quantum computers is still in its infancy, but experiments have been carried out in which quantum computational operations were executed on a very small number of qubits.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Quantum computing is very much a possibility, and if it does become a reality then the &amp;quot;ceiling&amp;quot; may get just a little higher.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7cj7d", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7cj7d/", "num_reports": null, "stickied": false, "created": 1422787698.0, "author_flair_text": null, "created_utc": 1422758898.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7cdf5", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co77dtu", "score": 0, "approved_by": null, "downs": 0, "body": "Well that's no way of looking at it. I could say, \"Firearms today aren't a big deal, but you'll notice that we went from the .357 magnum in 1935 to the .44 magnum in the 1960s, to the .50 AE in the 90s, to the even more poewrful .500 magnum in the 2000s. Therefore can you say in fifty years, or a century from now, we wouldn't have created a pistol so big that one bullet is big enough to hit everybody?\"\n\nYou can do this with anything, like engine capacity and pressure in cars, keeping the curve of development going well beyond what's possible into size and pressures that match a star.\n\nThe problem is that folks are assuming there is no ceiling to computing or mathematics, and that such a tendency means there's no limits on computing. This should probably be viewed as our ignorance, not actual infinite capability.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well that&amp;#39;s no way of looking at it. I could say, &amp;quot;Firearms today aren&amp;#39;t a big deal, but you&amp;#39;ll notice that we went from the .357 magnum in 1935 to the .44 magnum in the 1960s, to the .50 AE in the 90s, to the even more poewrful .500 magnum in the 2000s. Therefore can you say in fifty years, or a century from now, we wouldn&amp;#39;t have created a pistol so big that one bullet is big enough to hit everybody?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;You can do this with anything, like engine capacity and pressure in cars, keeping the curve of development going well beyond what&amp;#39;s possible into size and pressures that match a star.&lt;/p&gt;\n\n&lt;p&gt;The problem is that folks are assuming there is no ceiling to computing or mathematics, and that such a tendency means there&amp;#39;s no limits on computing. This should probably be viewed as our ignorance, not actual infinite capability.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7cdf5", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7cdf5/", "num_reports": null, "stickied": false, "created": 1422787375.0, "author_flair_text": "25\u2206", "created_utc": 1422758575.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co77dtu", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "mrgoodnighthairdo", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 4, "approved_by": null, "downs": 0, "body": "&gt;Part one...\n\nSure, an AI would not currently have the means to become a threat to humanity even if it were possible to have that desire.\n\nBut I hardly believe the Elon Musk or Hawkins thinks that artificial intelligence will threaten mankind within the next decade or two.\n\nBut what about fifty years? What about a century from now? What are our systems going to be like? Are we still gonna be using analog computers, or will quantum processors be a thing? Whatever the case, it's pretty clear that humanity is working towards a paperless and completely connected world. \n\nI don't know much about quantum computers, but I read an article about their development and, if they become a reality, then it'll likely change the AI question.\n\nCan you seriously say definitively that AI will not become a threat to humanity in the next hundred years? Maybe within the next two centuries?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Part one...&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Sure, an AI would not currently have the means to become a threat to humanity even if it were possible to have that desire.&lt;/p&gt;\n\n&lt;p&gt;But I hardly believe the Elon Musk or Hawkins thinks that artificial intelligence will threaten mankind within the next decade or two.&lt;/p&gt;\n\n&lt;p&gt;But what about fifty years? What about a century from now? What are our systems going to be like? Are we still gonna be using analog computers, or will quantum processors be a thing? Whatever the case, it&amp;#39;s pretty clear that humanity is working towards a paperless and completely connected world. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know much about quantum computers, but I read an article about their development and, if they become a reality, then it&amp;#39;ll likely change the AI question.&lt;/p&gt;\n\n&lt;p&gt;Can you seriously say definitively that AI will not become a threat to humanity in the next hundred years? Maybe within the next two centuries?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co77dtu", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co77dtu/", "num_reports": null, "stickied": false, "created": 1422777426.0, "author_flair_text": null, "created_utc": 1422748626.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7lfnc", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7kt2j", "score": 1, "approved_by": null, "downs": 0, "body": "Answered [here.](http://np.reddit.com/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7l9f5)", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Answered &lt;a href=\"http://np.reddit.com/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7l9f5\"&gt;here.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7lfnc", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7lfnc/", "num_reports": null, "stickied": false, "created": 1422811218.0, "author_flair_text": "25\u2206", "created_utc": 1422782418.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7kt2j", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "almightySapling", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 2, "approved_by": null, "downs": 0, "body": "Why don't humans count?\n\nI mean, every single problem you have stated could equally be applied to our own human evolution, every single one, yet it should be clear that we humans are capable of mass destruction, self-improvement, and contemplation of the infinite and higher-order logic.\n\nWhat process allowed us to avoid all the pitfalls that you claim exist for AI?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why don&amp;#39;t humans count?&lt;/p&gt;\n\n&lt;p&gt;I mean, every single problem you have stated could equally be applied to our own human evolution, every single one, yet it should be clear that we humans are capable of mass destruction, self-improvement, and contemplation of the infinite and higher-order logic.&lt;/p&gt;\n\n&lt;p&gt;What process allowed us to avoid all the pitfalls that you claim exist for AI?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7kt2j", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7kt2j/", "num_reports": null, "stickied": false, "created": 1422808551.0, "author_flair_text": "7\u2206", "created_utc": 1422779751.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 8, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 6, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": -5, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7f8xe", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7f6k5", "score": 2, "approved_by": null, "downs": 0, "body": "The simulated environment can have aspects which connect to external reality. The point /u/SevenAugust was making was that any idea that because humans will go insane from lack of sensory input isn't relevant. \n\nSo now, will you deal with the central question? Why are you concerned about uploads but not AI? ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The simulated environment can have aspects which connect to external reality. The point &lt;a href=\"/u/SevenAugust\"&gt;/u/SevenAugust&lt;/a&gt; was making was that any idea that because humans will go insane from lack of sensory input isn&amp;#39;t relevant. &lt;/p&gt;\n\n&lt;p&gt;So now, will you deal with the central question? Why are you concerned about uploads but not AI? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7f8xe", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f8xe/", "num_reports": null, "stickied": false, "created": 1422793254.0, "author_flair_text": "9\u2206", "created_utc": 1422764454.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 5, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": "", "user_reports": [], "saved": false, "id": "co7f9dl", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "SevenAugust", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7f6k5", "score": 5, "approved_by": null, "downs": 0, "body": "It could have our internet in the sim. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It could have our internet in the sim. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7f9dl", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f9dl/", "num_reports": null, "stickied": false, "created": 1422793283.0, "author_flair_text": null, "created_utc": 1422764483.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7g0gy", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "[deleted]", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7f6k5", "score": 2, "approved_by": null, "downs": 0, "body": "It doesn't even need to be simulated in that way. Link the brain to an android body, or a few cameras and microphones, and let it interact with humans.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It doesn&amp;#39;t even need to be simulated in that way. Link the brain to an android body, or a few cameras and microphones, and let it interact with humans.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": false, "subreddit": "changemyview", "name": "t1_co7g0gy", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7g0gy/", "num_reports": null, "stickied": false, "created": 1422794894.0, "author_flair_text": null, "created_utc": 1422766094.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7f6k5", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7f3xj", "score": 0, "approved_by": null, "downs": 0, "body": "That doesn't translate to non-sim insight, or adaptation beyond the sim, knowledge of it, etc.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That doesn&amp;#39;t translate to non-sim insight, or adaptation beyond the sim, knowledge of it, etc.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7f6k5", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f6k5/", "num_reports": null, "stickied": false, "created": 1422793114.0, "author_flair_text": "25\u2206", "created_utc": 1422764314.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7f3xj", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "SevenAugust", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7eq83", "score": 3, "approved_by": null, "downs": 0, "body": "The only software needed to fix the problem you describe could be modeled off of existing virtual reality software. A virtual body and virtual world could be programmed to enable the mind to experiment. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The only software needed to fix the problem you describe could be modeled off of existing virtual reality software. A virtual body and virtual world could be programmed to enable the mind to experiment. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7f3xj", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f3xj/", "num_reports": null, "stickied": false, "created": 1422792965.0, "author_flair_text": null, "created_utc": 1422764165.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 6, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 0, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 4, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": false, "replies": "", "user_reports": [], "saved": false, "id": "co7pwtm", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7igf9", "score": 4, "approved_by": null, "downs": 0, "body": "&gt; We're talking about AI, not speculating about robots\n\nThe issues are interrelated. An AI if it is going to do anything will need some form of inputs. Moreover this particularly subthread was discussing this particularly in the context of uploads. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;We&amp;#39;re talking about AI, not speculating about robots&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The issues are interrelated. An AI if it is going to do anything will need some form of inputs. Moreover this particularly subthread was discussing this particularly in the context of uploads. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7pwtm", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7pwtm/", "num_reports": null, "stickied": false, "created": 1422830925.0, "author_flair_text": "9\u2206", "created_utc": 1422802125.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7igf9", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7et0k", "score": 0, "approved_by": null, "downs": 0, "body": "We're talking about AI, not speculating about robots.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re talking about AI, not speculating about robots.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7igf9", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7igf9/", "num_reports": null, "stickied": false, "created": 1422800615.0, "author_flair_text": "25\u2206", "created_utc": 1422771815.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7et0k", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7eq83", "score": 6, "approved_by": null, "downs": 0, "body": "Why do you think it needs to be a \"brain in a box\" with no external input? ", "edited": 1422764105.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why do you think it needs to be a &amp;quot;brain in a box&amp;quot; with no external input? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7et0k", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7et0k/", "num_reports": null, "stickied": false, "created": 1422792332.0, "author_flair_text": "9\u2206", "created_utc": 1422763532.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 3, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7f921", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "[deleted]", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7eq83", "score": 3, "approved_by": null, "downs": 0, "body": "The sensory input can be emulated as well.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The sensory input can be emulated as well.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": false, "subreddit": "changemyview", "name": "t1_co7f921", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7f921/", "num_reports": null, "stickied": false, "created": 1422793263.0, "author_flair_text": null, "created_utc": 1422764463.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": "", "user_reports": [], "saved": false, "id": "co7ouqm", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "SevenAugust", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7eq83", "score": 2, "approved_by": null, "downs": 0, "body": "People are probably downvoting because the concern has been answered redundantly without response from you", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People are probably downvoting because the concern has been answered redundantly without response from you&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ouqm", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ouqm/", "num_reports": null, "stickied": false, "created": 1422827490.0, "author_flair_text": null, "created_utc": 1422798690.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7eq83", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7c4nd", "score": -5, "approved_by": null, "downs": 0, "body": "Nah. Humans go insane without sensory imput (hallucinations, confusion). A brain in a box would be glitchy if a perfect human brain sim.\n\nEdit: Downvote away, but I'm talking about facts of neuroscience that are readily available. The human mind is dependent on the body to remain coherent to reality, and many thinking processes are based on navigation and such things. If you are put in solitary confinement, you'll not be able to tell the difference between months and hours.", "edited": 1422783546.0, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": "comment score below threshold", "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nah. Humans go insane without sensory imput (hallucinations, confusion). A brain in a box would be glitchy if a perfect human brain sim.&lt;/p&gt;\n\n&lt;p&gt;Edit: Downvote away, but I&amp;#39;m talking about facts of neuroscience that are readily available. The human mind is dependent on the body to remain coherent to reality, and many thinking processes are based on navigation and such things. If you are put in solitary confinement, you&amp;#39;ll not be able to tell the difference between months and hours.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7eq83", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7eq83/", "num_reports": null, "stickied": false, "created": 1422792160.0, "author_flair_text": "25\u2206", "created_utc": 1422763360.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7c4nd", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "SevenAugust", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7bpfn", "score": 6, "approved_by": null, "downs": 0, "body": "But if a human can be dangerous, and a computer can be made functionally identical to a human, surely a computer can be dangerous. No?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But if a human can be dangerous, and a computer can be made functionally identical to a human, surely a computer can be dangerous. No?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7c4nd", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7c4nd/", "num_reports": null, "stickied": false, "created": 1422786881.0, "author_flair_text": null, "created_utc": 1422758081.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7bpfn", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co761rl", "score": 0, "approved_by": null, "downs": 0, "body": "Yes. It's of least concern to me.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes. It&amp;#39;s of least concern to me.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7bpfn", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7bpfn/", "num_reports": null, "stickied": false, "created": 1422786044.0, "author_flair_text": "25\u2206", "created_utc": 1422757244.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "more", "data": {"count": 2, "name": "t1_co80urz", "id": "co80urz", "parent_id": "t1_co761rl", "depth": 1, "children": ["co80urz"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "co761rl", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "SevenAugust", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 8, "approved_by": null, "downs": 0, "body": "Have you heard of the concept of whole brain emulation?", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you heard of the concept of whole brain emulation?&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co761rl", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co761rl/", "num_reports": null, "stickied": false, "created": 1422774798.0, "author_flair_text": null, "created_utc": 1422745998.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 2, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 0, "name": "t1__", "id": "_", "parent_id": "t1_co81yje", "depth": 10, "children": []}}], "before": null}}, "user_reports": [], "saved": false, "id": "co81yje", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co81n8q", "score": 1, "approved_by": null, "downs": 0, "body": "&gt;Humans aren't the apex predator because we're faster or stronger but because we're smarter. So what do you expect should happen when something smarter shows up?\n\nWell that's precisely what I'm saying, the AI cannot be smarter because it navigates information according to rules programmed by humans. Regarding the other aspects of your post, I believe the AI is \"smarter\" than people like a notepad has a better \"memory\" or a gun is \"stronger\". It's not actually smarter.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Humans aren&amp;#39;t the apex predator because we&amp;#39;re faster or stronger but because we&amp;#39;re smarter. So what do you expect should happen when something smarter shows up?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Well that&amp;#39;s precisely what I&amp;#39;m saying, the AI cannot be smarter because it navigates information according to rules programmed by humans. Regarding the other aspects of your post, I believe the AI is &amp;quot;smarter&amp;quot; than people like a notepad has a better &amp;quot;memory&amp;quot; or a gun is &amp;quot;stronger&amp;quot;. It&amp;#39;s not actually smarter.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co81yje", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co81yje/", "num_reports": null, "stickied": false, "created": 1422854968.0, "author_flair_text": "25\u2206", "created_utc": 1422826168.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 9, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co81n8q", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7skqx", "score": 1, "approved_by": null, "downs": 0, "body": "Computers can already match humans at many things. Heck, you even mentioned chess in your example. And computers are even getting as good as humans our on things we consider to be highly human specific, like image recognition. By many metrics [the best image recognition systems rival humans](http://lesswrong.com/lw/lj1/open_thread_jan_12_jan_18_2015/bvc9). Moreover, the AI can take advantage of many discoveries and ideas humans have already made. If we've already discovered say a very efficient algorithm for something, it doesn't need to reinvent that algorithm if it has access to that data.\n\nFurthermore, the entire reason that recursive self-improvement is plausible for AI in a way it isn't for humans is because the AI aren't purely evolved kludges. A combination of evolved systems and careful planning means that an AI with full ability to look at its own software can make modifications as necessary in ways humans cannot. \n\n&gt; with literally no serious physical or computational survival issues that cause it to fail\n\nThis just amounts to saying that the first few attempts at AIs may have serious survival issues. No one questions that. But you seem to assume that any AI will no matter what have such problems. So imagine for a moment that we make an AI that gets past basic survival issues. What do you then expect to happen? \n\n&gt;  it becomes a serious hazard to Earth's apex predator\n\nHumans aren't the apex predator because we're faster or stronger but because we're smarter. So what do you expect should happen when something smarter shows up? ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Computers can already match humans at many things. Heck, you even mentioned chess in your example. And computers are even getting as good as humans our on things we consider to be highly human specific, like image recognition. By many metrics &lt;a href=\"http://lesswrong.com/lw/lj1/open_thread_jan_12_jan_18_2015/bvc9\"&gt;the best image recognition systems rival humans&lt;/a&gt;. Moreover, the AI can take advantage of many discoveries and ideas humans have already made. If we&amp;#39;ve already discovered say a very efficient algorithm for something, it doesn&amp;#39;t need to reinvent that algorithm if it has access to that data.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, the entire reason that recursive self-improvement is plausible for AI in a way it isn&amp;#39;t for humans is because the AI aren&amp;#39;t purely evolved kludges. A combination of evolved systems and careful planning means that an AI with full ability to look at its own software can make modifications as necessary in ways humans cannot. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;with literally no serious physical or computational survival issues that cause it to fail&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This just amounts to saying that the first few attempts at AIs may have serious survival issues. No one questions that. But you seem to assume that any AI will no matter what have such problems. So imagine for a moment that we make an AI that gets past basic survival issues. What do you then expect to happen? &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;it becomes a serious hazard to Earth&amp;#39;s apex predator&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Humans aren&amp;#39;t the apex predator because we&amp;#39;re faster or stronger but because we&amp;#39;re smarter. So what do you expect should happen when something smarter shows up? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co81n8q", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co81n8q/", "num_reports": null, "stickied": false, "created": 1422854399.0, "author_flair_text": "9\u2206", "created_utc": 1422825599.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 8, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7skqx", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7s79f", "score": 1, "approved_by": null, "downs": 0, "body": "Yes digital is being viewed magically because you're asking a computer and some instructions to match millions of years of evolution in a box without adapting or being shaped by actual physical forces, and then emerge smarter and more capable in reality within years of its hatching and finding itself better adapted and smarter with literally *no* serious physical or computational survival issues that cause *it* to fail--rather, it becomes a serious hazard to Earth's apex predator. All hubris and very magical.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes digital is being viewed magically because you&amp;#39;re asking a computer and some instructions to match millions of years of evolution in a box without adapting or being shaped by actual physical forces, and then emerge smarter and more capable in reality within years of its hatching and finding itself better adapted and smarter with literally &lt;em&gt;no&lt;/em&gt; serious physical or computational survival issues that cause &lt;em&gt;it&lt;/em&gt; to fail--rather, it becomes a serious hazard to Earth&amp;#39;s apex predator. All hubris and very magical.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7skqx", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7skqx/", "num_reports": null, "stickied": false, "created": 1422837446.0, "author_flair_text": "25\u2206", "created_utc": 1422808646.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 7, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7s79f", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7s49a", "score": 2, "approved_by": null, "downs": 0, "body": "No. Strong AI here means AI with around normal human baseline intelligence or slightly higher than baseline intelligence. The concern then is that it will engage in recursive self-improvement to what you are calling \"god-mode\" or will wipe out humans or drastically curtail our value well before reaching \"god-mode\"- one doesn't need much power for example to synthesize novel viruses and the like. \n\nAnd no, digital information isn't being \"magically\"- if anything the problem here is that you are viewing analog systems like humans as somehow special and magical in a way that cannot be duplicated by other systems. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No. Strong AI here means AI with around normal human baseline intelligence or slightly higher than baseline intelligence. The concern then is that it will engage in recursive self-improvement to what you are calling &amp;quot;god-mode&amp;quot; or will wipe out humans or drastically curtail our value well before reaching &amp;quot;god-mode&amp;quot;- one doesn&amp;#39;t need much power for example to synthesize novel viruses and the like. &lt;/p&gt;\n\n&lt;p&gt;And no, digital information isn&amp;#39;t being &amp;quot;magically&amp;quot;- if anything the problem here is that you are viewing analog systems like humans as somehow special and magical in a way that cannot be duplicated by other systems. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7s79f", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7s79f/", "num_reports": null, "stickied": false, "created": 1422836642.0, "author_flair_text": "9\u2206", "created_utc": 1422807842.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 6, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7s49a", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7riv8", "score": 1, "approved_by": null, "downs": 0, "body": "We've been through this. However I think by strong AI you mean god-mode AI without any limits because digital information is being viewed magically and without limits.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been through this. However I think by strong AI you mean god-mode AI without any limits because digital information is being viewed magically and without limits.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7s49a", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7s49a/", "num_reports": null, "stickied": false, "created": 1422836460.0, "author_flair_text": "25\u2206", "created_utc": 1422807660.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 5, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7riv8", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7qypr", "score": 1, "approved_by": null, "downs": 0, "body": "&gt; Because that's not my view.\n\nReally? So if I'm following you you believe that even if one takes for granted that their will be strong AI, there's no reason to think it will be a threat, yes? Why? ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Because that&amp;#39;s not my view.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Really? So if I&amp;#39;m following you you believe that even if one takes for granted that their will be strong AI, there&amp;#39;s no reason to think it will be a threat, yes? Why? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7riv8", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7riv8/", "num_reports": null, "stickied": false, "created": 1422835103.0, "author_flair_text": "9\u2206", "created_utc": 1422806303.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 4, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7qypr", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7q00r", "score": 1, "approved_by": null, "downs": 0, "body": "Because that's not my view.", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because that&amp;#39;s not my view.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7qypr", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7qypr/", "num_reports": null, "stickied": false, "created": 1422833741.0, "author_flair_text": "25\u2206", "created_utc": 1422804941.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 3, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7q00r", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "JoshuaZ1", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7j1l3", "score": 2, "approved_by": null, "downs": 0, "body": "&gt; It's far more likely to struggle with even basic aspect of reality\n\nYou seem to be repeatedly conflating two different claims: one that strong AI will not be a threat and two that strong AI will not happen. As far I can tell almost all your arguments are really on the second of these two issues, so why not state that explicitly? ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s far more likely to struggle with even basic aspect of reality&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You seem to be repeatedly conflating two different claims: one that strong AI will not be a threat and two that strong AI will not happen. As far I can tell almost all your arguments are really on the second of these two issues, so why not state that explicitly? &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7q00r", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7q00r/", "num_reports": null, "stickied": false, "created": 1422831172.0, "author_flair_text": "9\u2206", "created_utc": 1422802372.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 2, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7j1l3", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "WhenSnowDies", "can_mod_post": false, "send_replies": true, "parent_id": "t1_co7ikwy", "score": 1, "approved_by": null, "downs": 0, "body": "I think that these fears are unfounded because they assume that AI will be like a \"perpetual motion\" data machine, with no noise, \"friction\", or ability to err and build on error unto nonsense and it crashes. I think it'll be laden with flaws that cause the system consequences, not man.\n\nPeople are assuming that it could be very perfect. I find that silly. It's far more likely to struggle with even basic aspect of reality, hence the frame problem. ", "edited": false, "author_flair_css_class": null, "collapsed": false, "is_submitter": true, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think that these fears are unfounded because they assume that AI will be like a &amp;quot;perpetual motion&amp;quot; data machine, with no noise, &amp;quot;friction&amp;quot;, or ability to err and build on error unto nonsense and it crashes. I think it&amp;#39;ll be laden with flaws that cause the system consequences, not man.&lt;/p&gt;\n\n&lt;p&gt;People are assuming that it could be very perfect. I find that silly. It&amp;#39;s far more likely to struggle with even basic aspect of reality, hence the frame problem. &lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7j1l3", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7j1l3/", "num_reports": null, "stickied": false, "created": 1422802289.0, "author_flair_text": "25\u2206", "created_utc": 1422773489.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 1, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7ikwy", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "Kraggen", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 1, "approved_by": null, "downs": 0, "body": "I'll argue that the reason that Artificial Intelligence might in fact be a very real problem is because we don't properly understand how we define intelligence.  Intelligence isn't an easily quantifiable sum and while it does pertain to knowledge it isn't limited to it, but rather seems to additionally encompass the ability to discern, learn and ascertain.   \n\nShould a sentient, non-compliant creature hard-lined or wirelessly connected to the vast sums of the internet gain the ability to utilize all of these things then the options for it are limitless and thus threatening.\n\nEven should it never become some Terminator-esque threat (which I think most would agree is unlikely) the rapid and unyielding expansion of human knowledge purveying from such a thing can and will be destructive in and of itself.  Right now we begin to see how much is lost when an expert can be duped by a ten-year-old that has access to google.  \n\nWhen, down the computing evolutionary line, humans are no longer responsible for the bulk of exploratory thinking and creation what negative effects might that have for the human race as a whole?  It's very likely that an overwhelming majority will be entirely dependent on systems that nobody knows how to operate any longer and therein lies the real danger of artificial intelligence.", "edited": false, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll argue that the reason that Artificial Intelligence might in fact be a very real problem is because we don&amp;#39;t properly understand how we define intelligence.  Intelligence isn&amp;#39;t an easily quantifiable sum and while it does pertain to knowledge it isn&amp;#39;t limited to it, but rather seems to additionally encompass the ability to discern, learn and ascertain.   &lt;/p&gt;\n\n&lt;p&gt;Should a sentient, non-compliant creature hard-lined or wirelessly connected to the vast sums of the internet gain the ability to utilize all of these things then the options for it are limitless and thus threatening.&lt;/p&gt;\n\n&lt;p&gt;Even should it never become some Terminator-esque threat (which I think most would agree is unlikely) the rapid and unyielding expansion of human knowledge purveying from such a thing can and will be destructive in and of itself.  Right now we begin to see how much is lost when an expert can be duped by a ten-year-old that has access to google.  &lt;/p&gt;\n\n&lt;p&gt;When, down the computing evolutionary line, humans are no longer responsible for the bulk of exploratory thinking and creation what negative effects might that have for the human race as a whole?  It&amp;#39;s very likely that an overwhelming majority will be entirely dependent on systems that nobody knows how to operate any longer and therein lies the real danger of artificial intelligence.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7ikwy", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7ikwy/", "num_reports": null, "stickied": false, "created": 1422800953.0, "author_flair_text": "1\u2206", "created_utc": 1422772153.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}, {"kind": "t1", "data": {"subreddit_id": "t5_2w2s8", "approved_at_utc": null, "ups": 1, "mod_reason_by": null, "banned_by": null, "removal_reason": null, "link_id": "t3_2uchba", "likes": null, "no_follow": true, "replies": {"kind": "Listing", "data": {"after": null, "whitelist_status": "all_ads", "modhash": "", "dist": null, "children": [{"kind": "more", "data": {"count": 3, "name": "t1_co7ee0h", "id": "co7ee0h", "parent_id": "t1_co7e1zb", "depth": 1, "children": ["co7ee0h"]}}], "before": null}}, "user_reports": [], "saved": false, "id": "co7e1zb", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": true, "report_reasons": null, "author": "funmaker0206", "can_mod_post": false, "send_replies": true, "parent_id": "t3_2uchba", "score": 1, "approved_by": null, "downs": 0, "body": "Ok but Bill Gates, Elon Musk, and Stephan Hawking aren't afraid of them turning on us they are afraid of the unknown concequences that can happen with a super intelligent AI.   \n  \nTake nukes for example. There are many who are outspoken about how they could destroy us all because if left unchecked they have the potential to cause a great deal of harm. Same with AI it can pose as a great danger because of the power that it can become.", "edited": false, "author_flair_css_class": " points", "collapsed": false, "is_submitter": false, "collapsed_reason": null, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok but Bill Gates, Elon Musk, and Stephan Hawking aren&amp;#39;t afraid of them turning on us they are afraid of the unknown concequences that can happen with a super intelligent AI.   &lt;/p&gt;\n\n&lt;p&gt;Take nukes for example. There are many who are outspoken about how they could destroy us all because if left unchecked they have the potential to cause a great deal of harm. Same with AI it can pose as a great danger because of the power that it can become.&lt;/p&gt;\n&lt;/div&gt;", "subreddit_type": "public", "can_gild": true, "subreddit": "changemyview", "name": "t1_co7e1zb", "score_hidden": false, "permalink": "/r/changemyview/comments/2uchba/cmv_artificial_intelligence_wont_be_a_problem/co7e1zb/", "num_reports": null, "stickied": false, "created": 1422790759.0, "author_flair_text": "1\u2206", "created_utc": 1422761959.0, "subreddit_name_prefixed": "r/changemyview", "controversiality": 0, "depth": 0, "mod_reports": [], "mod_note": null, "distinguished": null}}], "before": null}}]